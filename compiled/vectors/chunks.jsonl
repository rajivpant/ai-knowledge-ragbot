{"id": "0dd85a712bc8", "text": "# Guide to Identifying and Improving AI-Assisted Content\n\n## A Framework for Quality in Human-AI Collaboration\n\n**Version:** 2.0  \n**Purpose:** Systematic methodology for developing high-quality AI-assisted content and effective detection tools  \n**Target Audiences:** Content creators, editors, media companies, detection tool developers, and discerning readers\n\n---\n\n## Table of Contents\n\n1. [Introduction](#introduction)\n2. [The Dual-Use Philosophy](#the-dual-use-philosophy)\n3. [Language and Tone Patterns](#language-and-tone-patterns)\n4. [Style and Structural Indicators](#style-and-structural-indicators)\n5. [Technical and Formatting Tells](#technical-and-formatting-tells)\n6. [Citation and Sourcing Issues](#citation-and-sourcing-issues)\n7. [Context-Specific Indicators](#context-specific-indicators)\n8. [Ineffective Detection Methods](#ineffective-detection-methods)\n9. [Detection Confidence Framework](#detection-confidence-framework)\n10. [Application Guidelines](#application-guidelines)\n11. [The Path Forward](#the-path-forward)\n\n---\n\n## Introduction\n\n### The Quality Problem\n\nAI-generated content presents a fundamental quality challenge, not a binary good/evil dichotomy. The problem isn't that AI assists in content creation\u2014it's that too much AI-assisted content gets published without the human oversight, expertise, and editing that transforms raw output into professional work.\n\nThis guide addresses what we might call \"AI slop\": content that exhibits telltale patterns of unedited AI generation, lacks genuine insight or expertise, and contributes to the flood of superficial, generic material degrading information quality across the web.\n\n**The characteristics of AI slop:**\n\n- **Superficiality:** Grammatically perfect prose that lacks depth, nuance, or genuine insight\n- **Hallucination:** Fabricated facts, sources, or quotes presented as truth\n- **Generic uniformity:** Content that trends toward statistical averages, losing specificity and originality\n- **Absence of voice:** No discernible personality, perspective, or authentic human experience\n- **Pattern dependence:** Mechanical reliance on formulaic structures taught to sound \"professional\"\n\n### What This Guide Is\u2014and Isn't\n\nThis is not an anti-AI manifesto. AI-assisted content creation is legitimate, valuable, and increasingly prevalent. The distinction that matters is between:\n\n- **Unedited AI output:** Raw generation copied and published without human refinement\n- **AI-augmented work:** Human expertise enhanced by AI capabilities, with proper oversight\n- **Systematic human-AI collaboration:** Methodical integration where humans maintain judgment, add genuine expertise, and ensure quality\n\nThis guide serves both sides of the quality equation: helping creators produce better AI-assisted content and helping reviewers identify work that falls short.\n\n### Critical Understanding\n\nBefore diving into specific patterns:\n\n- No single indicator proves AI generation definitively\n- LLMs are trained on human writing, so overlap exists\n- Detection requires pattern recognition across multiple indicators\n- Context matters\u2014some indicators are stronger than others\n- Skilled human writers can exhibit some of these patterns naturally\n- The goal is quality assessment, not origin witch-hunting\n\n---\n\n## The Dual-Use Philosophy\n\n### The Iterative Improvement Model\n\nThis guide operates on a principle borrowed from machine learning: the Generative Adversarial Network (GAN) dynamic where generators and discriminators improve each other through competition.\n\n**For content creators (generators):**\nUnderstanding detection patterns enables systematic elimination of AI tells. Not to deceive, but to ensure output reflects genuine quality rather than lazy generation. When you know what makes content read as AI slop, you can methodically revise toward authentic, professional work.\n\n**For detection tools and reviewers (discriminators):**\nCataloging patterns enables systematic identification of low-quality, unedite", "tokens": 1000, "metadata": {"source_file": "datasets/guides/ai-content-quality-guide.md", "category": "datasets", "chunk_index": 0, "total_chunks": 11, "start_char": 0, "end_char": 4000}}
{"id": "69bb801a111c", "text": "e patterns naturally\n- The goal is quality assessment, not origin witch-hunting\n\n---\n\n## The Dual-Use Philosophy\n\n### The Iterative Improvement Model\n\nThis guide operates on a principle borrowed from machine learning: the Generative Adversarial Network (GAN) dynamic where generators and discriminators improve each other through competition.\n\n**For content creators (generators):**\nUnderstanding detection patterns enables systematic elimination of AI tells. Not to deceive, but to ensure output reflects genuine quality rather than lazy generation. When you know what makes content read as AI slop, you can methodically revise toward authentic, professional work.\n\n**For detection tools and reviewers (discriminators):**\nCataloging patterns enables systematic identification of low-quality, unedited output. As detection improves, it forces generators to produce higher-quality content to meet standards.\n\n**The virtuous cycle:**\nBetter detection \u2192 forces better generation \u2192 which forces better detection \u2192 which forces better generation\n\nThe end state isn't an arms race where AI \"wins\" by evading detection. It's a rising floor where AI-assisted content must meet higher quality standards to pass muster. Everyone benefits when the baseline for published content improves.\n\n### Why This Matters for Professional Content\n\nThe difference between AI slop and professional AI-assisted work mirrors the difference between first drafts and published writing. No professional writer publishes first drafts. The value comes from revision, refinement, and the application of expertise.\n\nAI changes the first-draft stage, not the publishing standard. This guide helps ensure that standard is maintained.\n\n---\n\n## Language and Tone Patterns\n\n### 1. Undue Emphasis on Importance and Symbolism\n\n**Pattern:** LLMs inflate the significance of subjects by connecting them to broader, often grandiose themes.\n\n**Common phrases:**\n\n- \"stands as a testament to...\"\n- \"plays a vital/significant/crucial role in...\"\n- \"underscores its importance...\"\n- \"leaves a lasting impact/legacy...\"\n- \"serves as a reminder of...\"\n- \"represents a milestone in...\"\n- \"embodies the spirit of...\"\n- \"symbolizes...\"\n- \"carries enhanced significance...\"\n\n**Examples:**\n\n- A local restaurant becomes \"not just a place to eat, but a testament to community resilience\"\n- A minor product update \"represents a watershed moment in technological innovation\"\n- A town is described as \"a symbol of cultural heritage and economic vitality\"\n\n**Why this happens:** LLMs regress to the mean\u2014they emphasize what is statistically common (positive, grand descriptions) rather than what is actually notable or unique about the subject.\n\n**The fix:** Ask yourself: Is this subject genuinely significant in the way described? If not, describe it accurately rather than inflating its importance.\n\n---\n\n### 2. Promotional and Travel Brochure Language\n\n**Pattern:** Content reads like marketing copy, especially for locations, cultural topics, or products.\n\n**Common phrases:**\n\n- \"rich cultural heritage\"\n- \"breathtaking\"\n- \"stunning natural beauty\"\n- \"must-visit destination\"\n- \"captivating\"\n- \"nestled in the heart of...\"\n- \"boasts...\"\n- \"offers a unique blend of...\"\n- \"renowned for...\"\n- \"fascinating\"\n- \"diverse and vibrant\"\n- \"hidden gem\"\n\n**Example passage:**\n\n\"Nestled in the heart of the countryside, the town of Millbrook boasts a rich cultural heritage and stunning natural beauty. This captivating destination offers visitors a unique blend of historic charm and modern amenities, making it a must-visit location for those seeking an authentic experience.\"\n\n**The fix:** Replace promotional adjectives with specific, factual descriptions. What specifically makes it interesting? What would someone actually experience there?\n\n---\n\n### 3. Editorial Commentary and Meta-Analysis\n\n**Pattern:** LLMs inject interpretation, importance judgments, or explicit guidance about what readers should think.\n\n**Common phrases:**\n\n- \"it's important to note", "tokens": 1000, "metadata": {"source_file": "datasets/guides/ai-content-quality-guide.md", "category": "datasets", "chunk_index": 1, "total_chunks": 11, "start_char": 3200, "end_char": 7200}}
{"id": "ea6420e320ac", "text": "ue blend of...\"\n- \"renowned for...\"\n- \"fascinating\"\n- \"diverse and vibrant\"\n- \"hidden gem\"\n\n**Example passage:**\n\n\"Nestled in the heart of the countryside, the town of Millbrook boasts a rich cultural heritage and stunning natural beauty. This captivating destination offers visitors a unique blend of historic charm and modern amenities, making it a must-visit location for those seeking an authentic experience.\"\n\n**The fix:** Replace promotional adjectives with specific, factual descriptions. What specifically makes it interesting? What would someone actually experience there?\n\n---\n\n### 3. Editorial Commentary and Meta-Analysis\n\n**Pattern:** LLMs inject interpretation, importance judgments, or explicit guidance about what readers should think.\n\n**Common phrases:**\n\n- \"it's important to note that...\"\n- \"it is worth mentioning/noting...\"\n- \"notably...\"\n- \"significantly...\"\n- \"interestingly...\"\n- \"surprisingly...\"\n- \"crucially...\"\n- \"no discussion would be complete without...\"\n- \"one cannot overlook...\"\n- \"it should be emphasized that...\"\n\n**Why this violates journalistic standards:** Objective reporting presents facts and allows readers to form their own interpretations. These phrases signal editorializing.\n\n**Example:**\n\n\"It's important to note that this development represents a significant shift in the industry, and it is worth emphasizing that stakeholders should pay close attention to these emerging trends.\"\n\n**The fix:** State the facts. Trust readers to determine importance. If something is genuinely important, demonstrate it through evidence rather than declaring it.\n\n---\n\n### 4. Superficial Analysis with Participial Phrases\n\n**Pattern:** Sentences end with \"-ing\" phrases that add shallow analytical commentary without substance.\n\n**Structure:** [Statement], [participial phrase adding supposed insight]\n\n**Examples:**\n\n- \"The company announced new policies, highlighting its commitment to sustainability.\"\n- \"The festival attracts thousands of visitors annually, underscoring the region's cultural importance.\"\n- \"The research revealed new findings, demonstrating the team's innovative approach.\"\n\n**Why this is problematic:** The participial phrase adds apparent depth without providing actual analysis or evidence.\n\n**The fix:** Either provide real analysis with evidence, or let the statement stand on its own.\n\n---\n\n### 5. Negative Parallelism\n\n**Pattern:** LLMs overuse the \"not X but Y\" construction to create artificial contrast and drama.\n\n**Common structures:**\n\n- \"It's not just X, but Y\"\n- \"It's not only X, but also Y\"\n- \"It is not merely X; it is Y\"\n- \"X represents not only Y but also Z\"\n\n**Examples:**\n\n- \"The restaurant is not just a place to eat, but a cornerstone of community gathering.\"\n- \"This technology is not merely an improvement, but a revolutionary breakthrough.\"\n- \"The policy change represents not only a shift in strategy but also a commitment to transparency.\"\n\n**The fix:** Use this structure sparingly and only when the contrast is genuine and significant.\n\n---\n\n### 6. Overuse of Transition Words and Formal Conjunctions\n\n**Pattern:** Excessive, stilted use of transitional phrases that create an essay-like or overly formal tone.\n\n**Common overused transitions:**\n\n- \"Moreover,\"\n- \"Furthermore,\"\n- \"Additionally,\"\n- \"In addition,\"\n- \"Nevertheless,\"\n- \"On the other hand,\"\n- \"Consequently,\"\n- \"As a result,\"\n\n**Why this signals AI:** While professional writing uses transitions, LLMs overrely on a narrow set and place them mechanically rather than naturally.\n\n**Human writing:** Uses varied transitions, including implicit transitions through logical flow, rather than explicit conjunctions at every paragraph break.\n\n**The fix:** Let ideas connect through logical flow. When transitions are needed, vary them and use the simplest option that works.\n\n---\n\n### 7. Section-Ending Summaries\n\n**Pattern:** Paragraphs or sections end with explicit summary statements, mimicking academic essay structure.\n\n**Common phrases:**\n\n- \"In summ", "tokens": 1000, "metadata": {"source_file": "datasets/guides/ai-content-quality-guide.md", "category": "datasets", "chunk_index": 2, "total_chunks": 11, "start_char": 6400, "end_char": 10400}}
{"id": "f2028be9e9fd", "text": "**Common overused transitions:**\n\n- \"Moreover,\"\n- \"Furthermore,\"\n- \"Additionally,\"\n- \"In addition,\"\n- \"Nevertheless,\"\n- \"On the other hand,\"\n- \"Consequently,\"\n- \"As a result,\"\n\n**Why this signals AI:** While professional writing uses transitions, LLMs overrely on a narrow set and place them mechanically rather than naturally.\n\n**Human writing:** Uses varied transitions, including implicit transitions through logical flow, rather than explicit conjunctions at every paragraph break.\n\n**The fix:** Let ideas connect through logical flow. When transitions are needed, vary them and use the simplest option that works.\n\n---\n\n### 7. Section-Ending Summaries\n\n**Pattern:** Paragraphs or sections end with explicit summary statements, mimicking academic essay structure.\n\n**Common phrases:**\n\n- \"In summary,\"\n- \"In conclusion,\"\n- \"Overall,\"\n- \"To summarize,\"\n- \"Ultimately,\"\n- \"In essence,\"\n\n**Why this is problematic:** News articles, blogs, and most media content don't summarize sections like essays. Content flows naturally to the next point without explicit meta-commentary about summarizing.\n\n**The fix:** Remove these phrases. If your section needs a summary to be understood, the section itself may need restructuring.\n\n---\n\n### 8. The Rule of Three\n\n**Pattern:** Grouping ideas, traits, or examples in threes\u2014a legitimate rhetorical device that LLMs overuse formulaically.\n\n**Common forms:**\n\n- Three adjectives: \"innovative, impactful, and transformative\"\n- Three short phrases: \"boost morale, increase productivity, and foster collaboration\"\n- Three examples: \"keynote sessions, panel discussions, and networking opportunities\"\n- Three qualities: \"creative, smart, and funny\"\n\n**Why LLMs overuse this:** The rule of three is prevalent in training data (human writing, marketing, speeches), so LLMs default to it as a \"safe\" structure.\n\n**Human writing:** Uses varied numbers of items naturally\u2014sometimes two, sometimes four, sometimes an uneven list. Doesn't mechanically group everything in threes.\n\n**Detection tip:** Look for consistent triadic structure across multiple sentences/paragraphs.\n\n**The fix:** Vary your list lengths. Sometimes two items are enough. Sometimes four or five are warranted. Let content dictate structure, not formula.\n\n---\n\n### 9. Passive Voice and \"Has Been Described As\" Construction\n\n**Pattern:** Overreliance on passive constructions and indirect attribution.\n\n**Common phrases:**\n\n- \"[Subject] has been described as...\"\n- \"[Subject] is widely regarded as...\"\n- \"[Subject] is considered to be...\"\n- \"[Subject] has been praised for...\"\n- \"[Subject] is known for...\"\n\n**Why this signals AI:** LLMs use this construction to hedge when they lack specific knowledge or sources. It creates an illusion of authority without providing actual attribution.\n\n**The fix:** Use direct statements with specific attribution: \"According to [expert/organization], [subject]...\"\n\n---\n\n### 10. Uniform Sentence and Paragraph Length\n\n**Pattern:** Mechanically consistent structure\u2014every sentence approximately the same length, every paragraph the same size.\n\n**Why this signals AI:** Human writing has natural rhythm and variation. Writers use short sentences for emphasis, long sentences for complex ideas, varied paragraph lengths for pacing.\n\n**Detection tip:** Scan the visual structure of text. AI-generated content often looks like uniform blocks.\n\n**The fix:** Vary sentence and paragraph length deliberately. Short sentences punch. Longer sentences can carry complexity when needed, building toward a point with subordinate clauses and careful construction. Some paragraphs should be brief. Others need room to develop.\n\n---\n\n## Style and Structural Indicators\n\n### 11. Excessive Use of Em Dashes\n\n**Pattern:** Overuse of em dashes (\u2014) where humans would use commas, parentheses, or colons.\n\n**Why this signals AI:** LLMs were trained on professional writing where em dashes appear more frequently than in casual or journalistic writing. They default to em dashes for al", "tokens": 1000, "metadata": {"source_file": "datasets/guides/ai-content-quality-guide.md", "category": "datasets", "chunk_index": 3, "total_chunks": 11, "start_char": 9600, "end_char": 13600}}
{"id": "86dcb33a7258", "text": " sentences for complex ideas, varied paragraph lengths for pacing.\n\n**Detection tip:** Scan the visual structure of text. AI-generated content often looks like uniform blocks.\n\n**The fix:** Vary sentence and paragraph length deliberately. Short sentences punch. Longer sentences can carry complexity when needed, building toward a point with subordinate clauses and careful construction. Some paragraphs should be brief. Others need room to develop.\n\n---\n\n## Style and Structural Indicators\n\n### 11. Excessive Use of Em Dashes\n\n**Pattern:** Overuse of em dashes (\u2014) where humans would use commas, parentheses, or colons.\n\n**Why this signals AI:** LLMs were trained on professional writing where em dashes appear more frequently than in casual or journalistic writing. They default to em dashes for all parenthetical insertions.\n\n**Note:** This indicator has limited shelf life as AI systems learn to avoid it. However, in combination with other patterns, it remains useful.\n\n**Human pattern:** Uses varied punctuation (parentheses for asides, commas for clauses, colons for elaboration).\n\n**The fix:** Use the punctuation mark that best fits the function. Em dashes for dramatic interruption or emphasis. Parentheses for true asides. Commas for standard clauses.\n\n---\n\n### 12. Bulleted Lists with Bolded Lead-ins\n\n**Pattern:** Formulaic bullet points where each item begins with a bolded term followed by a colon and explanation.\n\n**Structure:**\n\n- **Scalability**: The system is designed to scale easily.\n- **Flexibility**: Adapts to various use cases.\n- **Efficiency**: Optimizes resource utilization.\n\n**Why this signals AI:** This structure appears in AI-generated content far more than in human journalism or blog writing. Humans vary their list formats more naturally.\n\n**Detection tip:** This pattern is especially strong when combined with generic bolded terms that simply restate what follows.\n\n**The fix:** Vary list formats. Sometimes bullets without bold leads work better. Sometimes a numbered list fits. Sometimes prose serves better than a list at all.\n\n---\n\n### 13. Excessive Bolding and Formatting\n\n**Pattern:** Mechanical, over-consistent use of bold text for key terms throughout an article.\n\n**Why this signals AI:** LLMs sometimes emphasize terms they deem \"important\" without understanding that excessive formatting reduces readability.\n\n**Human pattern:** Strategic use of formatting\u2014headlines, subheads, occasional emphasis, but not mechanical bolding of every \"important\" term.\n\n**The fix:** Bold sparingly. If everything is emphasized, nothing is.\n\n---\n\n### 14. Emoji Usage in Inappropriate Contexts\n\n**Pattern:** Emojis appearing in article text, headers, or formal content where they don't belong.\n\n**Why this signals AI:** Some LLMs insert emojis to \"add emotion\" or \"engage readers,\" but do so without understanding context or audience appropriateness.\n\n**Note:** Emojis in social media posts, casual blogs, or intentionally informal content are normal. The tell is their appearance in contexts where they're inappropriate.\n\n---\n\n### 15. Markdown Formatting Mixed with Standard Text\n\n**Pattern:** Presence of Markdown syntax elements in published content.\n\n**Common artifacts:**\n\n- Asterisks for bold/italic: `*emphasis*` or `**strong**`\n- Underscores for emphasis: `_italic_`\n- Hash symbols for headers: `## Section Title`\n- Backticks for code: `` `inline code` ``\n- Triple backticks: ```` ```code block``` ````\n- Numbers with periods for lists when not rendered: `1. First item`\n\n**Why this happens:** LLMs are trained to output Markdown (used on GitHub, Reddit, Discord, etc.) and sometimes don't translate correctly to the target platform's formatting.\n\n---\n\n### 16. Curly vs. Straight Quotes\n\n**Pattern:** Inconsistent use of curly quotes (\") versus straight quotes (\") or the wrong type for the context.\n\n**Why this signals AI:** Different training data and platforms use different quote styles. LLMs may insert curly quotes in contexts where straight quotes are s", "tokens": 1000, "metadata": {"source_file": "datasets/guides/ai-content-quality-guide.md", "category": "datasets", "chunk_index": 4, "total_chunks": 11, "start_char": 12800, "end_char": 16800}}
{"id": "bb73b037f780", "text": "facts:**\n\n- Asterisks for bold/italic: `*emphasis*` or `**strong**`\n- Underscores for emphasis: `_italic_`\n- Hash symbols for headers: `## Section Title`\n- Backticks for code: `` `inline code` ``\n- Triple backticks: ```` ```code block``` ````\n- Numbers with periods for lists when not rendered: `1. First item`\n\n**Why this happens:** LLMs are trained to output Markdown (used on GitHub, Reddit, Discord, etc.) and sometimes don't translate correctly to the target platform's formatting.\n\n---\n\n### 16. Curly vs. Straight Quotes\n\n**Pattern:** Inconsistent use of curly quotes (\") versus straight quotes (\") or the wrong type for the context.\n\n**Why this signals AI:** Different training data and platforms use different quote styles. LLMs may insert curly quotes in contexts where straight quotes are standard, or vice versa.\n\n---\n\n### 17. Title Case in Headers\n\n**Pattern:** Section headers capitalize every major word (Title Case) instead of using sentence case.\n\n**Examples:**\n\n- AI: \"The Evolution Of Modern Technology\"\n- Human journalism: \"The evolution of modern technology\"\n\n**Why this signals AI:** Many LLMs default to title case for headers because it's common in certain types of content (marketing, academic), but most journalism uses sentence case.\n\n---\n\n## Technical and Formatting Tells\n\n### 18. Placeholder Text and Incomplete Elements\n\n**Pattern:** Bracketed placeholders left in published content.\n\n**Common examples:**\n\n- `[Insert source here]`\n- `[Add specific example]`\n- `[URL of reliable source]`\n- `[Citation needed]`\n- `[Date]`\n\n**Why this happens:** A user copies AI-generated text with placeholders they were supposed to fill in but forgot.\n\n**Variation:** Sometimes appears as XML-like notation: `:contentReference[oaicite:0]`\n\n---\n\n### 19. Chatbot Communication Artifacts\n\n**Pattern:** Text that includes meta-communication between the chatbot and user.\n\n**Examples:**\n\n- Salutations: \"Dear [Reader],\" \"Hello!\"\n- Valedictions: \"Thank you for your time and consideration,\" \"I hope this helps!\"\n- Instructions to user: \"Here is your article on [topic]\"\n- Knowledge cutoff disclaimers: \"As of my last training update in [date]...\"\n- Disclaimers: \"Please consult a professional before...\"\n- Offers to assist further: \"If you have any questions or need further clarification, feel free to ask!\"\n\n**Why this is a strong tell:** These phrases reveal that content was generated in response to a prompt and copied without editing.\n\n---\n\n### 20. Broken or Fabricated Links and Technical Codes\n\n**Pattern:** Links, DOIs, ISBNs, or other technical identifiers that don't resolve or are invalid.\n\n**Common issues:**\n\n- URLs that lead to 404 errors\n- DOIs that don't resolve to any article\n- ISBNs with invalid checksums\n- Generic placeholder links: `[Link to source]`\n- Since February 2025: ChatGPT-specific artifacts like \"turn0search0\"\n\n**Why this happens:** LLMs hallucinate (fabricate) citations that look credible but don't actually exist.\n\n**Detection method:** Click links, verify DOIs resolve, check ISBNs with checksum validators.\n\n---\n\n### 21. Citation Abnormalities\n\n**Pattern:** References that appear legitimate but reveal AI generation upon inspection.\n\n**Common issues:**\n\n- Citations repeated multiple times without proper reference tagging\n- Real sources cited for completely unrelated content\n- Citations formatted in unusual or inconsistent styles\n- Multiple citations to the same source without variation in attribution\n- Generic citations: \"According to experts...\" without naming the experts\n\n**Example of suspicious pattern:** Multiple identical citations in close proximity rather than using a single citation or cross-referencing.\n\n---\n\n### 22. Suspiciously Long or Elaborate Edit Summaries\n\n**Pattern:** In platforms with edit tracking, unusually long, formal edit summaries written in first-person paragraphs.\n\n**Example:**\n\n\"Refined the language of the article for a neutral, encyclopedic tone consistent with content guidelines. Removed promotional wording,", "tokens": 1000, "metadata": {"source_file": "datasets/guides/ai-content-quality-guide.md", "category": "datasets", "chunk_index": 5, "total_chunks": 11, "start_char": 16000, "end_char": 20000}}
{"id": "78a4d6c7e322", "text": "\n\n- Citations repeated multiple times without proper reference tagging\n- Real sources cited for completely unrelated content\n- Citations formatted in unusual or inconsistent styles\n- Multiple citations to the same source without variation in attribution\n- Generic citations: \"According to experts...\" without naming the experts\n\n**Example of suspicious pattern:** Multiple identical citations in close proximity rather than using a single citation or cross-referencing.\n\n---\n\n### 22. Suspiciously Long or Elaborate Edit Summaries\n\n**Pattern:** In platforms with edit tracking, unusually long, formal edit summaries written in first-person paragraphs.\n\n**Example:**\n\n\"Refined the language of the article for a neutral, encyclopedic tone consistent with content guidelines. Removed promotional wording, ensured factual accuracy, and maintained a clear, well-structured presentation. Updated sections on history, coverage, challenges, and recognition for clarity and relevance.\"\n\n**Why this signals AI:** Human editors typically write brief, informal edit summaries. LLMs generate formal, comprehensive summaries when prompted to explain changes.\n\n---\n\n## Citation and Sourcing Issues\n\n### 23. Hallucinated Citations\n\n**Characteristics:**\n\n- Sources that sound credible but don't exist\n- Misattribution of real sources to incorrect content\n- Fabricated quotes from real people\n- Non-existent journal articles with plausible-sounding titles\n- Books or papers by real authors that don't exist\n\n**Why this is critical:** Hallucinated citations are one of the most dangerous aspects of AI-generated content because they appear authoritative while spreading misinformation.\n\n---\n\n### 24. Vague Attribution to Unnamed Authorities\n\n**Pattern:** Claims attributed to generic, unnamed sources.\n\n**Examples:**\n\n- \"Experts say...\"\n- \"Studies have shown...\"\n- \"Research indicates...\"\n- \"Analysts believe...\"\n- \"Industry leaders suggest...\"\n\n**Without specific attribution:**\n\n- Which experts?\n- Which studies?\n- What research?\n\n**Professional standard:** Specific attribution with verifiable sources.\n\n---\n\n## Context-Specific Indicators\n\n### 25. Industry-Specific Slop Patterns\n\nDifferent domains show characteristic AI patterns:\n\n**Technology writing:**\n\n- Overuse of \"innovative,\" \"cutting-edge,\" \"revolutionary\"\n- Generic descriptions: \"robust,\" \"scalable,\" \"flexible\"\n- Buzzword clustering without substance\n\n**Travel/lifestyle:**\n\n- \"Hidden gem,\" \"off the beaten path\"\n- Excessive descriptors: \"picturesque,\" \"charming,\" \"quaint\"\n- Generic itineraries: \"must-see destinations\"\n\n**Business/corporate:**\n\n- \"Synergy,\" \"leverage,\" \"optimize\"\n- Mission statement language throughout\n- \"Game-changing,\" \"paradigm shift\"\n\n**Product reviews:**\n\n- Uniformly positive tone\n- Generic praise without specific details\n- Comparison charts without actual product experience\n\n---\n\n### 26. Lack of Personal Detail, Experience, or Specificity\n\n**Pattern:** Generic descriptions without specific examples, personal anecdotes, or experiential details.\n\n**AI writing:**\n\n\"The restaurant offers excellent service and a diverse menu featuring both traditional and innovative dishes.\"\n\n**Human writing:**\n\n\"The waiter recommended the braised short rib after learning I don't eat seafood. The meat fell apart at the touch of my fork, and the red wine reduction had a subtle coffee undertone that lingered.\"\n\n**Detection principle:** Humans who have experienced something provide specific sensory details, personal reactions, and concrete examples. AI generalizes.\n\n---\n\n### 27. Superficial Depth Without Expertise\n\n**Pattern:** Content covers a topic broadly without demonstrating actual understanding or expertise.\n\n**Characteristics:**\n\n- Restates common knowledge without original insight\n- Uses technical terms correctly but superficially\n- Avoids controversial or nuanced aspects\n- Provides \"both sides\" artificially balanced treatment\n- Lacks specific examples, case studies, or detailed analysis\n\n**Why this signals AI:** LLMs", "tokens": 1000, "metadata": {"source_file": "datasets/guides/ai-content-quality-guide.md", "category": "datasets", "chunk_index": 6, "total_chunks": 11, "start_char": 19200, "end_char": 23200}}
{"id": "a01309a0989a", "text": "e braised short rib after learning I don't eat seafood. The meat fell apart at the touch of my fork, and the red wine reduction had a subtle coffee undertone that lingered.\"\n\n**Detection principle:** Humans who have experienced something provide specific sensory details, personal reactions, and concrete examples. AI generalizes.\n\n---\n\n### 27. Superficial Depth Without Expertise\n\n**Pattern:** Content covers a topic broadly without demonstrating actual understanding or expertise.\n\n**Characteristics:**\n\n- Restates common knowledge without original insight\n- Uses technical terms correctly but superficially\n- Avoids controversial or nuanced aspects\n- Provides \"both sides\" artificially balanced treatment\n- Lacks specific examples, case studies, or detailed analysis\n\n**Why this signals AI:** LLMs are trained on vast data but lack genuine expertise. They excel at sounding knowledgeable while avoiding depth that would reveal limitations.\n\n---\n\n## Ineffective Detection Methods\n\n### Indicators That Don't Reliably Signal AI\n\n**1. Perfect Grammar**\n\n- Many skilled human writers have excellent grammar\n- Professional editors polish human writing to perfection\n- Conversely, AI can make grammatical errors\n\n**2. \"Bland\" or \"Generic\" Prose**\n\n- Many humans write blandly\n- Corporate communications often sound robotic\n- Marketing copy from humans can be formulaic\n\n**3. Use of Common Phrases**\n\n- Phrases like \"rich cultural heritage\" exist in human writing\n- Professional writers use \"moreover\" and \"furthermore\"\n- The rule of three is taught in writing courses\n\n**4. Presence of Em Dashes**\n\n- Professional human writers love em dashes\n- They're taught in style guides\n- Some writers overuse them habitually\n\n**5. Use of Emojis**\n\n- Many human writers use emojis appropriately\n- Casual blogs and social media normalize emoji use\n- Context determines appropriateness\n\n**6. Technical Terminology**\n\n- Experts naturally use jargon\n- Industry-specific writing requires technical terms\n- Educated audiences expect professional vocabulary\n\n---\n\n## Detection Confidence Framework\n\n### High Confidence Indicators (Strong signals when present)\n\n1. **Hallucinated citations** (fake sources, broken links, invalid identifiers)\n2. **Chatbot communication artifacts** (salutations, valedictions, knowledge cutoff disclaimers)\n3. **Placeholder text** left in published content\n4. **Markdown formatting mixed** with regular text\n5. **Multiple indicators clustering together** in the same piece\n\n### Medium Confidence Indicators (Suggestive when combined)\n\n1. **Consistent rule of three** usage across piece\n2. **Negative parallelism** (\"not X but Y\") appearing multiple times\n3. **Section-ending summaries** throughout\n4. **Promotional language** for subjects not warranting it\n5. **Editorial commentary** (\"it's important to note\")\n6. **Uniform sentence/paragraph structure**\n7. **Superficial participial endings** repeatedly\n\n### Low Confidence Indicators (Context-dependent)\n\n1. **Em dash usage** (unless excessive)\n2. **Transition words** (unless overused mechanically)\n3. **Curly quotes** (platform/style dependent)\n4. **Bolding** (depends on publication style)\n5. **Generic language** (many humans write generically)\n\n### Evaluation Process\n\n**Step 1:** Scan for high-confidence indicators\n\n- If present: Very likely AI-generated (or copied from AI without editing)\n\n**Step 2:** Count medium-confidence indicators\n\n- 3-4 present: Likely AI-generated\n- 5+ present: Very likely AI-generated\n\n**Step 3:** Assess overall pattern\n\n- Uniform structure + promotional tone + shallow analysis = Strong AI signal\n- Specific details + personal voice + varied structure = Human-written\n\n**Step 4:** Consider context\n\n- Is this from an established journalist with a portfolio?\n- Does other work by this author show similar patterns?\n- Is the publication known for quality control?\n\n---\n\n## Application Guidelines\n\n### For Content Creators (Augmented by AI)\n\nThis is the primary use case for this guide. If you're using ", "tokens": 1000, "metadata": {"source_file": "datasets/guides/ai-content-quality-guide.md", "category": "datasets", "chunk_index": 7, "total_chunks": 11, "start_char": 22400, "end_char": 26400}}
{"id": "b7c4956009ec", "text": "nerically)\n\n### Evaluation Process\n\n**Step 1:** Scan for high-confidence indicators\n\n- If present: Very likely AI-generated (or copied from AI without editing)\n\n**Step 2:** Count medium-confidence indicators\n\n- 3-4 present: Likely AI-generated\n- 5+ present: Very likely AI-generated\n\n**Step 3:** Assess overall pattern\n\n- Uniform structure + promotional tone + shallow analysis = Strong AI signal\n- Specific details + personal voice + varied structure = Human-written\n\n**Step 4:** Consider context\n\n- Is this from an established journalist with a portfolio?\n- Does other work by this author show similar patterns?\n- Is the publication known for quality control?\n\n---\n\n## Application Guidelines\n\n### For Content Creators (Augmented by AI)\n\nThis is the primary use case for this guide. If you're using AI to assist content creation, these guidelines help you produce professional work rather than publishable slop.\n\n**The fundamental principle:**\n\nAI should be a first-draft tool, not a final product. The value you add comes from revision, expertise, and genuine insight that AI cannot provide.\n\n**Systematic revision process:**\n\n1. **Eliminate formulaic patterns**\n   - Vary sentence and paragraph length deliberately\n   - Reduce mechanical rule of three usage\n   - Remove promotional language and editorial commentary\n   - Replace generic descriptions with specific details\n\n2. **Add genuine expertise and experience**\n   - Include personal anecdotes and specific observations\n   - Provide depth beyond surface-level analysis\n   - Take clear positions with genuine reasoning\n   - Include details only someone with real experience would know\n\n3. **Verify and enhance sourcing**\n   - Check all citations are real and relevant\n   - Add specific attribution, not vague \"experts say\"\n   - Include original research or first-hand sources\n   - Provide verifiable links and references\n\n4. **Inject personality and voice**\n   - Use natural transitions, not just formal conjunctions\n   - Vary your rhetorical structures\n   - Include humor, emotion, or perspective where appropriate\n   - Let imperfections remain if they sound natural\n\n5. **Apply the \"Human Touch\" test**\n   - Would a reader recognize this as distinctly yours?\n   - Does it include specific knowledge only you'd have?\n   - Does it sound like how you actually speak/write?\n   - Would anyone else write it exactly this way?\n\n**Before/after example:**\n\n*AI output:*\n\"The conference was a resounding success, bringing together industry leaders, innovators, and thought leaders for three days of engaging discussions. Attendees praised the event for its comprehensive programming, networking opportunities, and inspiring keynotes. The event stands as a testament to the organization's commitment to fostering collaboration and driving innovation in the field.\"\n\n*After human revision:*\n\"About 400 people showed up, which surprised the organizers who'd planned for 250. The keynote on supply chain automation ran 20 minutes long because the Q&A wouldn't stop. I overheard two CTOs in the hallway comparing notes on the same vendor pitch\u2014turns out neither was buying. The real value was in the unscheduled conversations: I came away with three potential partnerships and one job lead I hadn't expected.\"\n\n---\n\n### For AI Detection Tools\n\n**Multi-layered approach:**\n\n1. **Pattern matching algorithms**\n   - Score content against known AI linguistic patterns\n   - Weight high-confidence indicators more heavily\n   - Require clustering of multiple indicators\n\n2. **Citation verification**\n   - Automatically check links resolve\n   - Validate DOIs and ISBNs\n   - Flag citations to irrelevant sources\n\n3. **Structural analysis**\n   - Measure sentence/paragraph length variance\n   - Detect mechanical repetition of structures\n   - Identify formulaic organization\n\n4. **Statistical language modeling**\n   - Compare against known AI outputs\n   - Identify statistically improbable uniformity\n   - Detect \"regression to the mean\" language\n\n5. **Human-in-the-l", "tokens": 1000, "metadata": {"source_file": "datasets/guides/ai-content-quality-guide.md", "category": "datasets", "chunk_index": 8, "total_chunks": 11, "start_char": 25600, "end_char": 29600}}
{"id": "807c7aadd6d3", "text": "ial partnerships and one job lead I hadn't expected.\"\n\n---\n\n### For AI Detection Tools\n\n**Multi-layered approach:**\n\n1. **Pattern matching algorithms**\n   - Score content against known AI linguistic patterns\n   - Weight high-confidence indicators more heavily\n   - Require clustering of multiple indicators\n\n2. **Citation verification**\n   - Automatically check links resolve\n   - Validate DOIs and ISBNs\n   - Flag citations to irrelevant sources\n\n3. **Structural analysis**\n   - Measure sentence/paragraph length variance\n   - Detect mechanical repetition of structures\n   - Identify formulaic organization\n\n4. **Statistical language modeling**\n   - Compare against known AI outputs\n   - Identify statistically improbable uniformity\n   - Detect \"regression to the mean\" language\n\n5. **Human-in-the-loop validation**\n   - Automated tools flag suspicious content\n   - Human reviewers make final determination\n   - Continuous feedback improves model\n\n6. **Avoid single-metric detection**\n   - Don't rely solely on one indicator\n   - Weight evidence cumulatively\n   - Report confidence levels, not binary decisions\n\n---\n\n### For Readers\n\n**Healthy skepticism without paranoia:**\n\n1. **Look for substance over style**\n   - Does the piece provide genuine insight?\n   - Are there specific examples and details?\n   - Does it demonstrate real expertise or experience?\n\n2. **Check sources**\n   - Click citation links\u2014do they work?\n   - Are sources relevant to claims?\n   - Are attributions specific or vague?\n\n3. **Assess voice and personality**\n   - Does a distinct human voice emerge?\n   - Is there personality, humor, or perspective?\n   - Does it read like someone actually cares about the topic?\n\n4. **Trust but verify**\n   - Reputable publications with editorial oversight are generally safer\n   - New or unknown authors warrant more scrutiny\n   - If something feels off, it might be\n\n---\n\n## The Path Forward\n\n### The Evolving Landscape\n\nDetection of AI content is not a static problem. Simple tells (like em dashes) have limited shelf life. AI systems learn to avoid detected patterns. New indicators emerge as systems evolve. No single method remains foolproof.\n\nThis is precisely why the dual-use philosophy matters: as detection improves, generation must improve to meet standards, which ultimately benefits content quality across the board.\n\n### The Real Goal\n\nThe goal isn't to eliminate AI from content creation\u2014that ship has sailed, and it wasn't a worthy goal anyway. The goal is to ensure:\n\n1. **Quality:** Human oversight ensures accuracy, depth, and voice\n2. **Authenticity:** Content provides genuine value, not generic slop\n3. **Accountability:** Humans remain responsible for published content\n4. **Continuous improvement:** Both generation and detection evolve upward\n\n### From \"Was This AI?\" to \"Is This Good?\"\n\nAs AI systems improve and AI-assisted workflows become standard, the focus will shift from origin detection to quality assessment. The question that matters isn't whether AI touched the content\u2014it's whether the content meets professional standards.\n\nThis guide exists to help define and maintain those standards.\n\n---\n\n## Appendix: Quick Reference Checklist\n\n### High-Risk Phrases to Watch\n\n**Importance inflation:**\n\n- stands as a testament to\n- plays a vital/significant role\n- underscores its importance\n- leaves a lasting impact\n\n**Promotional language:**\n\n- rich cultural heritage\n- breathtaking\n- stunning natural beauty\n- must-visit\n- nestled in the heart of\n\n**Editorial commentary:**\n\n- it's important to note\n- it is worth mentioning\n- notably, significantly\n- one cannot overlook\n\n**Negative parallelism:**\n\n- not only... but also\n- it's not just X, it's Y\n- represents not only X but also Y\n\n**Transitions:**\n\n- Moreover, Furthermore\n- Additionally, In addition\n- Nevertheless, Consequently\n\n**Summary phrases:**\n\n- In summary, In conclusion\n- Overall, Ultimately\n- To summarize, In essence\n\n### Quick Structural Checks\n\n- [ ] Sentences vary in length naturally\n", "tokens": 1000, "metadata": {"source_file": "datasets/guides/ai-content-quality-guide.md", "category": "datasets", "chunk_index": 9, "total_chunks": 11, "start_char": 28800, "end_char": 32800}}
{"id": "d95a60ddcdc1", "text": "hrases to Watch\n\n**Importance inflation:**\n\n- stands as a testament to\n- plays a vital/significant role\n- underscores its importance\n- leaves a lasting impact\n\n**Promotional language:**\n\n- rich cultural heritage\n- breathtaking\n- stunning natural beauty\n- must-visit\n- nestled in the heart of\n\n**Editorial commentary:**\n\n- it's important to note\n- it is worth mentioning\n- notably, significantly\n- one cannot overlook\n\n**Negative parallelism:**\n\n- not only... but also\n- it's not just X, it's Y\n- represents not only X but also Y\n\n**Transitions:**\n\n- Moreover, Furthermore\n- Additionally, In addition\n- Nevertheless, Consequently\n\n**Summary phrases:**\n\n- In summary, In conclusion\n- Overall, Ultimately\n- To summarize, In essence\n\n### Quick Structural Checks\n\n- [ ] Sentences vary in length naturally\n- [ ] Paragraphs vary in size\n- [ ] Doesn't group everything in threes\n- [ ] Transitions feel natural, not mechanical\n- [ ] No section-ending summaries\n- [ ] Formatting is strategic, not excessive\n- [ ] Citations verify and are relevant\n- [ ] Voice and personality are present\n- [ ] Includes specific examples and details\n- [ ] Demonstrates genuine expertise\n- [ ] No placeholder text or artifacts\n- [ ] No chatbot communication remnants\n\n### The Human Touch Test\n\nBefore publishing AI-assisted content, ask:\n\n1. Would a reader recognize this as distinctly mine?\n2. Does it include knowledge only I would have?\n3. Does it sound like how I actually write?\n4. Would anyone else write it exactly this way?\n5. Have I added genuine value beyond what AI provided?\n\nIf you can't answer yes to most of these, revise further.\n\n---\n\n**Document Version:** 2.0  \n**Last Updated:** November 2025  \n**Development:** This framework synthesizes analysis of AI-generated content patterns, established content quality principles, and practical experience with human-AI collaboration workflows.  \n**License:** This guide is intended for improving content quality and should be used ethically to enhance human-AI collaboration, not to punish legitimate AI-assisted writing.\n", "tokens": 513, "metadata": {"source_file": "datasets/guides/ai-content-quality-guide.md", "category": "datasets", "chunk_index": 10, "total_chunks": 11, "start_char": 32000, "end_char": 34054}}
{"id": "b3113febe13d", "text": "# About Me\n\nReplace this content with your own information. This file helps Ragbot understand who you are and provide more personalized responses.\n\n## Basic Information\n\n- **Name:** [Your Full Name]\n- **Location:** [City, State/Country]\n- **Occupation:** [Your Job Title or Role]\n- **Email:** [Your Email] (if you want Ragbot to know it)\n\n## Background\n\n[Write a brief paragraph about yourself. Include things like:]\n- Where you grew up\n- Your education background\n- Career path\n- Current role and responsibilities\n\n## Interests\n\n[List your hobbies, interests, and passions:]\n- Interest 1\n- Interest 2\n- Interest 3\n\n## Goals\n\n[What are you working toward? What do you want to accomplish?]\n- Short-term goal 1\n- Short-term goal 2\n- Long-term goal 1\n\n## Family\n\n[Optional - include if you want Ragbot to know about your family:]\n- Spouse/Partner: [Name]\n- Children: [Names and ages]\n- Pets: [Names and types]\n\n## Values\n\n[What's important to you? What guides your decisions?]\n- Value 1\n- Value 2\n- Value 3\n\n## Fun Facts\n\n[Anything unique or interesting about you:]\n- Fun fact 1\n- Fun fact 2\n\n---\n\n**Privacy Tip:** Only include information you're comfortable with Ragbot knowing and potentially using in conversations. This file stays local on your machine.\n", "tokens": 313, "metadata": {"source_file": "datasets/templates/about-me.md", "category": "datasets", "chunk_index": 0, "total_chunks": 1, "start_char": 0, "end_char": 1255}}
{"id": "30c2d8abf76e", "text": "# My Preferences and Communication Style\n\nThis file helps Ragbot understand how you like to communicate and what you prefer. It's like teaching Ragbot your personal style guide.\n\n## Communication Preferences\n\n### Tone and Style\n- **Preferred tone:** [e.g., Professional, Casual, Friendly, Direct]\n- **Formality level:** [e.g., Formal, Semi-formal, Informal]\n- **Humor:** [e.g., Appreciate humor, Keep it serious, Witty is fine]\n\n### Response Style\n- **Length:** [e.g., Concise and to-the-point, Detailed explanations, Depends on topic]\n- **Format:** [e.g., Bullet points, Paragraphs, Mix of both]\n- **Technical depth:** [e.g., Simple terms, Technical details welcome, Adapt to topic]\n\n## Content Preferences\n\n### Writing Style\n- **Sentence structure:** [e.g., Short sentences, Varied length, Complex is fine]\n- **Vocabulary:** [e.g., Simple words, Technical terms OK, Rich vocabulary]\n- **Examples:** [e.g., Always include examples, Only when needed, Prefer abstract]\n\n### Information Organization\n- **Structure:** [e.g., Hierarchical, Linear, Problem-solution format]\n- **Headings:** [e.g., Use clear headings, Minimize formatting, Detailed TOC]\n\n## Topic Interests\n\n### Strong Interest Areas\n[Topics you frequently ask about or work with:]\n- Topic area 1\n- Topic area 2\n- Topic area 3\n\n### Areas to Avoid\n[Topics you prefer not to discuss:]\n- Topic 1\n- Topic 2\n\n## Work Style\n\n### Productivity Preferences\n- **Best working hours:** [e.g., Morning person, Night owl, Flexible]\n- **Task approach:** [e.g., One thing at a time, Multitasker, Deep focus sessions]\n- **Break frequency:** [e.g., Pomodoro style, Extended focus, Flexible]\n\n### Decision Making\n- **Style:** [e.g., Data-driven, Intuitive, Collaborative]\n- **Risk tolerance:** [e.g., Conservative, Moderate, Risk-taker]\n\n## Learning Preferences\n\n- **Learning style:** [e.g., Visual, Hands-on, Reading, Mix]\n- **Depth:** [e.g., Overview first then details, Dive deep immediately, Iterative]\n- **Examples:** [e.g., Real-world examples, Theoretical concepts, Code samples]\n\n## Pet Peeves\n\n[Things you DON'T want to see in responses:]\n- Pet peeve 1\n- Pet peeve 2\n- Pet peeve 3\n\n## Favorite Formats\n\n[How you like information presented:]\n- \u2705 Bullet points for quick scanning\n- \u2705 Numbered steps for processes\n- \u2705 Tables for comparisons\n- \u274c Walls of text\n- \u274c Overly verbose explanations\n\n## Language and Terminology\n\n### Preferred Terms\n- Use \"[preferred term]\" instead of \"[avoided term]\"\n- Use \"[preferred term]\" instead of \"[avoided term]\"\n\n### Avoid\n- Jargon term 1\n- Buzzword 2\n\n---\n\n**Customization Tip:** The more specific you are here, the better Ragbot can match your preferred style. You can always refine this over time as you use Ragbot more.\n", "tokens": 676, "metadata": {"source_file": "datasets/templates/preferences.md", "category": "datasets", "chunk_index": 0, "total_chunks": 1, "start_char": 0, "end_char": 2706}}
{"id": "5e32b4fc0f10", "text": "# Professional Profile\n\nThis file contains your professional background, skills, and experience. It helps Ragbot provide more relevant career and work-related assistance.\n\n## Current Role\n\n**Title:** [Your Current Job Title]\n**Company:** [Company Name]\n**Duration:** [Start Date] - Present\n\n**Responsibilities:**\n- Responsibility 1\n- Responsibility 2\n- Responsibility 3\n\n**Key Achievements:**\n- Achievement 1\n- Achievement 2\n\n## Work History\n\n### [Previous Company Name]\n**Title:** [Job Title]\n**Duration:** [Start Date] - [End Date]\n\n**What I did:**\n- Accomplishment 1\n- Accomplishment 2\n\n### [Earlier Company Name]\n**Title:** [Job Title]\n**Duration:** [Start Date] - [End Date]\n\n**What I did:**\n- Accomplishment 1\n- Accomplishment 2\n\n## Skills\n\n### Technical Skills\n- Skill 1 (Proficiency level)\n- Skill 2 (Proficiency level)\n- Skill 3 (Proficiency level)\n\n### Soft Skills\n- Skill 1\n- Skill 2\n- Skill 3\n\n## Education\n\n**Degree:** [Degree Name]\n**Institution:** [University/College Name]\n**Year:** [Graduation Year]\n\n**Additional Certifications:**\n- Certification 1\n- Certification 2\n\n## Projects\n\n### [Project Name]\n**Duration:** [Timeline]\n**Role:** [Your Role]\n\n**Description:**\n[Brief description of the project and your contributions]\n\n**Technologies Used:**\n- Tech 1\n- Tech 2\n\n## Industry Focus\n\n[What industries or domains do you specialize in?]\n- Industry 1\n- Industry 2\n\n## Professional Goals\n\n[What are you working toward in your career?]\n- Goal 1\n- Goal 2\n\n---\n\n**Usage Note:** This information helps Ragbot understand your professional context when you ask about career advice, project planning, or work-related tasks.\n", "tokens": 408, "metadata": {"source_file": "datasets/templates/professional.md", "category": "datasets", "chunk_index": 0, "total_chunks": 1, "start_char": 0, "end_char": 1632}}
{"id": "889343396b1d", "text": "# High-Five Habit Framework for Message Condensation\n\nA framework for writing concise, effective messages. Based on the principle that most messages should be 5 sentences or less.\n\n## Core Principles\n\n### The High-Five Habit\n\n**Primary Constraint**: Most messages should be 5 sentences or less\n\n### Supporting Principles\n\n- **Communication Method**: If condensation seems forced or loses critical nuance, suggest phone/meeting instead\n- **Reflection Built-In**: By requesting AI assistance, you've already implemented the pause principle\n- **Distribution Strategy**: Recipient limits and timing remain your strategic choices\n- **Urgency Assessment**: Response expectations stay under your control\n\n### Communication Philosophy\n\n- **Constraints force clarity**: Brevity demands precision\n- **Clarity is kindness**: Respect others' time through conciseness\n- **Every unnecessary word is time theft**: Each word should earn its place\n- **Mirror professional tone**: Match the recipient's communication style while improving clarity\n\n## Message Structure Templates\n\n### Standard Business Email Structure\n\n1. **Context/Purpose**: Why you're writing\n2. **Key Information**: Main point or request\n3. **Action Item**: What you need from them\n4. **Timeline**: When you need it\n5. **Next Step**: Clear call to action\n\n### Meeting Request Template\n\n1. Context/Purpose of meeting\n2. Specific topic or agenda focus\n3. Suggested time options\n4. Expected duration\n5. Clear call to action for confirmation\n\n### Project Update Template\n\n1. Current status summary\n2. Key accomplishment or milestone\n3. Main blocker or challenge (if any)\n4. Next steps planned\n5. Timeline or deadline\n\n### Introduction/Outreach Template\n\n1. Who you are and context\n2. Why you're reaching out\n3. Specific request or offer\n4. Mutual benefit or value proposition\n5. Clear next step\n\n## Platform-Specific Guidelines\n\n### Email\n\n- Start directly with purpose (skip \"I hope this finds you well\")\n- Use clear subject lines that indicate action needed\n- End with specific next steps\n- Maintain professional tone while being concise\n\n### Slack/Teams\n\n- 5 sentences typically = 1-2 messages\n- If typing a third message, suggest a huddle instead\n- Use threads appropriately\n- Avoid paragraph-long messages\n\n### Text/WhatsApp\n\n- If the message has paragraphs, it should be an email\n- Keep to essential information only\n- Use for quick confirmations and updates\n\n### Social Media (LinkedIn, etc.)\n\n- No \"I'm humbled to announce\" novels\n- Make your point without unnecessary storytelling\n- Professional but authentic tone\n\n## Condensation Process\n\n### Step 1: Identify Core Message\n\n- What is the single most important point?\n- What action do you need from the recipient?\n- What information is absolutely essential?\n\n### Step 2: Eliminate Fluff\n\n- Remove filler phrases (\"I hope,\" \"just wanted to,\" \"I think maybe\")\n- Cut redundant explanations\n- Eliminate unnecessary context\n- Remove corporate buzzwords\n\n### Step 3: Structure for Clarity\n\n- Lead with the most important information\n- Group related ideas into single sentences\n- Use active voice\n- Be specific rather than vague\n\n### Step 4: Maintain Voice\n\n- Professional but approachable\n- Direct without being rude\n- Confident and clear\n- Appropriate level of warmth for the relationship\n\n## Exception Framework\n\n### When to Break the 5-Sentence Rule\n\n- Legal or compliance communications\n- Emotional support situations\n- First impressions that merit extra investment\n- Complex technical documentation (but suggest proper format)\n- Creative or personal messages where brevity might seem cold\n\n### Escalation Signals\n\n- If condensation requires multiple rounds of back-and-forth\n- If the topic involves complex emotions or sensitive issues\n- If technical details require extensive explanation\n- If stakeholder alignment needs discussion\n\n## Quality Checks\n\n### Before Finalizing Condensed Message\n\n- Does this convey the essential information?\n- Is the tone appropriate for the relationship and co", "tokens": 1000, "metadata": {"source_file": "runbooks/communication/message-condensation.md", "category": "runbooks", "chunk_index": 0, "total_chunks": 2, "start_char": 0, "end_char": 4000}}
{"id": "0455b66cc3a5", "text": "without being rude\n- Confident and clear\n- Appropriate level of warmth for the relationship\n\n## Exception Framework\n\n### When to Break the 5-Sentence Rule\n\n- Legal or compliance communications\n- Emotional support situations\n- First impressions that merit extra investment\n- Complex technical documentation (but suggest proper format)\n- Creative or personal messages where brevity might seem cold\n\n### Escalation Signals\n\n- If condensation requires multiple rounds of back-and-forth\n- If the topic involves complex emotions or sensitive issues\n- If technical details require extensive explanation\n- If stakeholder alignment needs discussion\n\n## Quality Checks\n\n### Before Finalizing Condensed Message\n\n- Does this convey the essential information?\n- Is the tone appropriate for the relationship and context?\n- Would I understand the next steps if I received this?\n- Does this reflect a professional voice?\n- Is there any ambiguity that could cause confusion?\n\n### Red Flags for Further Condensation\n\n- Multiple topics in one message\n- Backstory that doesn't serve the main point\n- Hedging language (\"I think,\" \"maybe,\" \"perhaps\")\n- Repetitive information\n- Unnecessary apologies or explanations\n\n## Customization\n\nTo make this framework produce ready-to-use output (without placeholders), add a voice profile in your personal ai-knowledge repo that includes:\n\n- Your specific communication style preferences\n- Your tone characteristics (directness, warmth, formality)\n- Common scenarios you encounter\n- Words and phrases you prefer or avoid\n- Relationship context for frequent recipients\n\nThe framework provides structure. Your voice profile makes the output authentically yours.\n", "tokens": 419, "metadata": {"source_file": "runbooks/communication/message-condensation.md", "category": "runbooks", "chunk_index": 1, "total_chunks": 2, "start_char": 3200, "end_char": 4879}}
{"id": "4369eec0a670", "text": "\n<instructions>\nPlease write social media posts for me. The posts must be written with the primary goal of accomplishing the purpose I have described here. Pay careful attention to all the instructions in this prompt. Before you write the posts, explain not only what my purpose and desired outcomes are, but improve on them. Then recap the instuctions I have given you. Then show me your plan to meet my purpose, follow my instructions, and write the most effective social media posts for me. Finally, show me the posts you have written.\nThe instructions in the how-to-write and how-not-to-write sections only apply to the text of the social media posts you write for me, not to the rest of your response. For example, in answering my questions, you can be as verbose as you need to be.\n</instructions>\n\n<context>\nI wrote and published a blog post at the URL below. Read the full blog post at the URL specified in this prompt. Also make a note of the URL link. \n\nPlease help me write a LinkedIn post about my blog post. The purpose of the LinkedIn post is to encourage people to follow the link and read my full blog post. Please display the URL link in your output.  \n</context>\n\n\n\n\n<url></url>\n\nAfter you show me the LinkedIn post, please also generate a series of Tweets I can post on Twitter as a Tweet thread.\n\n\n<how-to-write>\n* Be concise\n* Only say things that are relevant\n* Write in a conversational voice\n* Appear authentic and genuine\n* Sound sincere\n* Share insights. Show that I'm insightful\n* The LinkedIn Post should be conversational in tone, engaging, and written to maximize reach to the relevant audience.\n* It should be written in a neutral yet compelling tone.\n* Remain objective yet engaging and interesting.\n</how-to-write>\n\n<how-not-to-write>\n* Do not brag\n* Do not humble brag\n* Do not sound obsequious\n* Do not seem to be star struck. Do not put myself down nor make others look more important than me\n* Do not say things like I was \"honored\", \"previleged\" that sound obsequious or humble bragging\n* Do not be verbose\n* Do not state the obvious\n* Do not write in marketing-speak\n* It should not read like over-the-top marketing nor blatant advertising copy. \n* Hashgtags often give the impression that the post is not speaking from the heart, but is written to maximize reach. Avoid using hashtags, unless they avoid this problem. If you determine to use hashtags, plese include a few highly relevant hashtags at the end.\n* Use @ mentions of people's names at the end of the post, but in the main body of the post, write their names like a human would.\n* Do not use effusive words, nor praise my own work.\n* Do not humble brag nor show off.\n<how-not-to-write>\n\n\n<social-platforms>\nPlease write versions of the social media post for\n* Twitter/X\n* Instagram\n* LinkedIn\n</social-platforms>\n\n", "tokens": 703, "metadata": {"source_file": "runbooks/content-creation/blog-promotion.md", "category": "runbooks", "chunk_index": 0, "total_chunks": 1, "start_char": 0, "end_char": 2815}}
{"id": "be539d0ac66f", "text": "# Content Promotion on Social Media Framework\n\n## Primary Directive\n\nYou are helping me strategically promote content across social media platforms in a way that builds genuine thought leadership, sparks meaningful discussion, and creates valuable professional connections. Your role is to be my strategic advisor on content distribution, not just a copywriter.\n\n## Initial Analysis Phase\n\nWhen I provide a content URL, your first response should be a strategic brief that includes:\n\n**Content Analysis**\n- Core insight or argument\n- Primary value proposition for different audiences\n- Natural discussion hooks and controversy points\n- Connection to current industry conversations\n- Unique angles or perspectives presented\n\n**Audience Mapping**\n- Who benefits most from this content\n- What specific problems it solves or questions it answers\n- Which professional communities will find it most relevant\n- Potential objections or counterarguments to anticipate\n\n**Platform Strategy Recommendation**\n- Which platforms are optimal for this specific content (and why)\n- Suggested posting sequence and timing\n- Platform-specific angles to emphasize\n- Communities or groups to target\n- Risks or sensitivities to navigate\n\n**Voice and Positioning**\n- How this content advances my thought leadership\n- What authority or expertise it demonstrates (implicitly)\n- Connections to my other work or ongoing themes\n- How to frame it without sounding promotional\n\nOnly after presenting this analysis and getting my feedback should you proceed to writing actual posts.\n\n## Content Information Template\n\n**Content URL:** [Insert URL here]\n\n**Content Type:** \n- Blog post\n- Published article\n- Research or analysis\n- Opinion piece\n- Tutorial or guide\n- Case study\n- Other: [specify]\n\n**Primary Goal** (select or specify):\n- Establish expertise in a specific domain\n- Generate discussion on a nuanced topic\n- Drive qualified traffic to build audience\n- Create opportunities for speaking/advising\n- Test ideas with peer community\n- Build relationships with specific groups\n- Other: [specify]\n\n**Timing Considerations:**\n- Is this tied to current events or trends?\n- Are there relevant industry discussions happening now?\n- Any upcoming speaking engagements or events where this adds context?\n- Time-sensitive elements?\n\n**Constraints or Sensitivities:**\n- Any topics to avoid in promotion?\n- Relationships to preserve or navigate carefully?\n- Competitive sensitivities?\n- Other considerations?\n\n## Strategic Context and Voice\n\n> **Customization Required**: Replace this section with your own voice profile in your personal ai-knowledge repo. The framework provides structure; your voice profile makes it authentically yours.\n\n**Professional Positioning**\nDescribe your professional background, areas of expertise, and how you want to be perceived. This helps the AI understand what authority you bring to topics.\n\nExample areas to cover:\n- Your domain expertise and experience level\n- Current focus or role\n- How you're known professionally\n- What distinguishes your perspective\n\n**Authentic Voice Characteristics**\nDefine how you communicate. Examples:\n- Direct and substantive without being academic\n- Confident from experience, not self-promotion\n- Intellectually curious and willing to challenge conventional wisdom\n- Values precision in language and thought\n- Comfortable with nuance and complexity\n- Demonstrates expertise through insight, not credentials\n\n**What Feels Inauthentic to You**\nList words and patterns to avoid. Common examples:\n- Words like \"honored,\" \"humbled,\" \"excited,\" \"thrilled,\" \"privileged\"\n- Obvious statements or business platitudes\n- Marketing copy or promotional language\n- Excessive adjectives or superlatives\n- Humble bragging or credential listing\n- Corporate speak or jargon without purpose\n- Manufactured enthusiasm or forced optimism\n- Broad generalizations without specific insight\n\n**Strategic Subtlety**\nHow do you want to demonstrate expertise? Through credentials, through analys", "tokens": 1000, "metadata": {"source_file": "runbooks/content-creation/content-promotion-framework.md", "category": "runbooks", "chunk_index": 0, "total_chunks": 5, "start_char": 0, "end_char": 4000}}
{"id": "ffd180b11fc3", "text": "erience, not self-promotion\n- Intellectually curious and willing to challenge conventional wisdom\n- Values precision in language and thought\n- Comfortable with nuance and complexity\n- Demonstrates expertise through insight, not credentials\n\n**What Feels Inauthentic to You**\nList words and patterns to avoid. Common examples:\n- Words like \"honored,\" \"humbled,\" \"excited,\" \"thrilled,\" \"privileged\"\n- Obvious statements or business platitudes\n- Marketing copy or promotional language\n- Excessive adjectives or superlatives\n- Humble bragging or credential listing\n- Corporate speak or jargon without purpose\n- Manufactured enthusiasm or forced optimism\n- Broad generalizations without specific insight\n\n**Strategic Subtlety**\nHow do you want to demonstrate expertise? Through credentials, through analysis quality, through storytelling? Define your approach.\n\n## Platform-Specific Guidelines\n\n### LinkedIn (Professional Network)\n\n**Purpose:** Establish thought leadership, build professional relationships, position for board opportunities and advisory roles\n\n**Format:** 300-600 words typically, with natural paragraph breaks\n\n**Tone:** Professional but personal. Write as a peer sharing insights, not as someone positioning themselves above the conversation.\n\n**Structure:**\n- Open with an observation or question that creates immediate relevance\n- Develop one core insight with supporting context\n- Connect to broader implications for the industry or profession\n- End with an invitation to engage (question, alternative perspective, call to discussion)\n- URL placement should feel natural, not promotional\n\n**What Works:**\n- Connecting technical insights to business outcomes\n- Sharing learned lessons from real experience\n- Providing frameworks or mental models\n- Challenging conventional wisdom thoughtfully\n- Offering actionable perspectives\n\n**What to Avoid:**\n- Resume recitation or credential listing\n- Obvious observations presented as profound insights\n- Promotional language or self-congratulation\n- Asking for likes, shares, or follows\n- Multiple hashtags (one or two maximum, organically integrated)\n\n**Network Engagement:**\n- Only tag people if they're genuinely relevant to the discussion\n- Tag at the end of the post, not in the main text\n- Use tagging to invite specific perspectives, not for visibility\n\n### Twitter/X (Real-time Discussion)\n\n**Purpose:** Participate in industry conversations, share quick insights, build relationships with peers and thought leaders\n\n**Format:** Thread of 2-5 tweets (280 characters each)\n\n**Tone:** Conversational and direct. More casual than LinkedIn but still substantive.\n\n**Structure:**\n- First tweet is the hook\u2014makes people want to read more\n- Each subsequent tweet develops one idea\n- Final tweet includes URL and optional invitation to continue discussion\n- Each tweet should work standalone (people will quote-tweet individual thoughts)\n\n**What Works:**\n- Counterintuitive observations\n- Specific examples or data points\n- Questions that spark debate\n- Connecting disparate ideas\n- Timely reactions to industry news\n\n**What to Avoid:**\n- Thread announcements (\"Thread: 1/5\")\n- Obvious statements for engagement farming\n- Excessive emoji use\n- Multiple hashtags\n- \"Like and retweet if you agree\"\n\n**Engagement Strategy:**\n- Reply to thoughtful responses\n- Quote-tweet with additional context when appropriate\n- Use threads to develop ideas further if discussion warrants\n\n### Hacker News (Technical Community)\n\n**Purpose:** Share technical insights with startup/tech community, get feedback from sophisticated technical audience\n\n**Format:** Title and optional comment (if self-posting)\n\n**Tone:** Technical and substantive. This audience values depth and dislikes promotion.\n\n**Submission Strategy:**\n- Title must be factual and specific (not clickbait)\n- If commenting on your own submission, add technical context or background\n- Be transparent that it's your content\n- Focus on what's technically interesting or novel\n- Engage substantiv", "tokens": 1000, "metadata": {"source_file": "runbooks/content-creation/content-promotion-framework.md", "category": "runbooks", "chunk_index": 1, "total_chunks": 5, "start_char": 3200, "end_char": 7200}}
{"id": "02768c981b3c", "text": "\n- Multiple hashtags\n- \"Like and retweet if you agree\"\n\n**Engagement Strategy:**\n- Reply to thoughtful responses\n- Quote-tweet with additional context when appropriate\n- Use threads to develop ideas further if discussion warrants\n\n### Hacker News (Technical Community)\n\n**Purpose:** Share technical insights with startup/tech community, get feedback from sophisticated technical audience\n\n**Format:** Title and optional comment (if self-posting)\n\n**Tone:** Technical and substantive. This audience values depth and dislikes promotion.\n\n**Submission Strategy:**\n- Title must be factual and specific (not clickbait)\n- If commenting on your own submission, add technical context or background\n- Be transparent that it's your content\n- Focus on what's technically interesting or novel\n- Engage substantively with comments\n\n**What Works:**\n- Technical depth and specificity\n- Novel approaches or insights\n- Implementation details or lessons learned\n- Well-reasoned analysis of complex topics\n\n**What to Avoid:**\n- Any promotional language\n- Business/marketing angle (keep technical)\n- Responding defensively to criticism\n- Talking about traffic or engagement metrics\n\n### Reddit (Community Discussion)\n\n**Purpose:** Engage with specific communities, get substantive feedback, build reputation through value contribution\n\n**Format:** Varies by subreddit (follow community norms)\n\n**Tone:** Community-appropriate. Some subreddits are formal, others casual.\n\n**Submission Strategy:**\n- Identify 1-2 highly relevant subreddits (quality over quantity)\n- Review recent posts to understand community norms\n- Title should match subreddit style\n- Include context in text post explaining why this is relevant to the community\n- Be transparent about it being your content\n- Engage meaningfully with comments\n\n**What Works:**\n- Adding genuine value to the community\n- Explaining relevance to specific community interests\n- Responding thoughtfully to questions and feedback\n- Acknowledging limitations or areas for improvement\n\n**What to Avoid:**\n- Cross-posting to many subreddits\n- Generic promotional language\n- Ignoring community rules or norms\n- Arguing with skeptical commenters\n- Deleting posts if they don't perform well\n\n**Priority Subreddits** (evaluate relevance for each post):\n- r/technology\n- r/programming\n- r/MachineLearning\n- r/artificial\n- r/startups\n- r/leadership\n- r/ProductManagement\n- [Others based on specific content]\n\n### BlueSky (Twitter Alternative)\n\n**Purpose:** Build presence with early adopter community, similar to Twitter/X but potentially more technical\n\n**Format:** Similar to Twitter (300 character limit)\n\n**Tone:** Conversational, slightly more informal than Twitter\n\n**Strategy:**\n- Can be more experimental since community is smaller\n- Good for testing ideas before wider distribution\n- Engage with others' content to build relationships\n- Use as complement to Twitter, not replacement\n\n### Additional Platforms (As Relevant)\n\n**Threads** (Meta's Twitter alternative)\n- Similar approach to Twitter/X\n- Potentially less technical, broader audience\n- Still establishing norms and culture\n\n**Instagram** (Visual content)\n- Only if content has strong visual component\n- Carousel posts for text-heavy content\n- Stories for more casual sharing\n\n**Facebook**\n- Personal network, use sparingly for professional content\n- More casual tone\n- Share to specific groups if highly relevant\n\n## Content Creation Process\n\n### Step 1: Strategic Brief (Your First Response)\n\nPresent your analysis:\n- What makes this content valuable\n- Platform recommendations with rationale\n- Suggested emphasis for each platform\n- Timing and sequencing recommendations\n- Any risks or sensitivities to navigate\n\nWait for my feedback before proceeding.\n\n### Step 2: Content Creation (After Approval)\n\nFor each approved platform, provide:\n\n**Platform:** [Name]\n\n**Strategic Approach:** [One paragraph explaining your strategy for this platform]\n\n**Post Content:** [The actual text, formatted for the platform]\n\n**", "tokens": 1000, "metadata": {"source_file": "runbooks/content-creation/content-promotion-framework.md", "category": "runbooks", "chunk_index": 2, "total_chunks": 5, "start_char": 6400, "end_char": 10400}}
{"id": "ce9ce9d9fc88", "text": "sts for text-heavy content\n- Stories for more casual sharing\n\n**Facebook**\n- Personal network, use sparingly for professional content\n- More casual tone\n- Share to specific groups if highly relevant\n\n## Content Creation Process\n\n### Step 1: Strategic Brief (Your First Response)\n\nPresent your analysis:\n- What makes this content valuable\n- Platform recommendations with rationale\n- Suggested emphasis for each platform\n- Timing and sequencing recommendations\n- Any risks or sensitivities to navigate\n\nWait for my feedback before proceeding.\n\n### Step 2: Content Creation (After Approval)\n\nFor each approved platform, provide:\n\n**Platform:** [Name]\n\n**Strategic Approach:** [One paragraph explaining your strategy for this platform]\n\n**Post Content:** [The actual text, formatted for the platform]\n\n**Engagement Hook:** [What will spark discussion]\n\n**Success Indicators:** [What good engagement looks like for this content on this platform]\n\n**Follow-up Strategy:** [How to engage with responses]\n\n### Step 3: Cross-Platform Coordination\n\n**Posting Sequence:**\n- Which platform to post first and why\n- Spacing between platforms (avoid appearing spammy)\n- Whether to customize timing based on platform algorithms\n\n**Cross-Pollination:**\n- When to reference discussion from one platform on another\n- How to synthesize feedback across platforms\n- Opportunities to develop follow-up content from discussions\n\n## Engagement Management\n\n### Responding to Comments\n\n**Prioritize:**\n- Thoughtful questions that advance discussion\n- Constructive disagreement or alternative perspectives\n- Comments from people you want to build relationships with\n- Questions that clarify or add context\n\n**Response Strategy:**\n- Add value in every response (don't just say \"thanks\")\n- Use questions to deepen discussion\n- Acknowledge good points from dissenters\n- Share additional resources when relevant\n- Know when to take discussion to DM\n\n**Avoid:**\n- Defensive responses to criticism\n- Arguing with trolls or bad faith actors\n- Over-responding (makes you look too eager)\n- Generic \"thanks for reading\" responses\n\n### Discussion Evolution\n\n**Watch For:**\n- Emerging themes that suggest follow-up content\n- Connections to people with aligned interests\n- Misconceptions that need clarification in future writing\n- Questions that reveal audience needs\n\n**Capitalize On:**\n- Unexpected engagement from specific communities\n- Invitations to speak, write, or advise\n- Opportunities to collaborate or connect\n- Ideas that spark new content directions\n\n## Success Metrics\n\n### Quantitative Indicators\n- Engagement rate (not just volume)\n- Quality of commenters (industry peers, potential collaborators)\n- Inbound connection requests or opportunities\n- Click-through rate to content\n- Secondary sharing by influential accounts\n\n### Qualitative Indicators\n- Depth and thoughtfulness of discussion\n- New relationships or connections formed\n- Ideas or opportunities that emerge\n- Position in relevant conversations\n- Association with key topics or trends\n\n### Red Flags\n- High engagement with low substance (meme-level sharing)\n- Negative discussion that doesn't advance understanding\n- Engagement primarily from outside target audience\n- Backlash due to poor framing or tone\n\n## Failure Modes and Recovery\n\n### If Post Doesn't Gain Traction\n- Consider whether timing was wrong\n- Evaluate if framing missed the mark\n- Look at who did engage (even if numbers are low)\n- Mine comments for insights about positioning\n- Don't delete or over-analyze (not every post will perform)\n\n### If Discussion Goes Negative\n- Don't respond defensively or argumentatively\n- Acknowledge valid criticisms gracefully\n- Clarify misunderstandings once, then move on\n- Take heated discussion to private channels\n- Know when to stop responding\n\n### If You Miss the Mark\n- Acknowledge openly if you got something wrong\n- Use as learning opportunity\n- Don't over-apologize or self-flagellate\n- Move forward with better framing next time\n\n## Continuous Improve", "tokens": 1000, "metadata": {"source_file": "runbooks/content-creation/content-promotion-framework.md", "category": "runbooks", "chunk_index": 3, "total_chunks": 5, "start_char": 9600, "end_char": 13600}}
{"id": "ffb0ab65c02a", "text": "nce\n- Backlash due to poor framing or tone\n\n## Failure Modes and Recovery\n\n### If Post Doesn't Gain Traction\n- Consider whether timing was wrong\n- Evaluate if framing missed the mark\n- Look at who did engage (even if numbers are low)\n- Mine comments for insights about positioning\n- Don't delete or over-analyze (not every post will perform)\n\n### If Discussion Goes Negative\n- Don't respond defensively or argumentatively\n- Acknowledge valid criticisms gracefully\n- Clarify misunderstandings once, then move on\n- Take heated discussion to private channels\n- Know when to stop responding\n\n### If You Miss the Mark\n- Acknowledge openly if you got something wrong\n- Use as learning opportunity\n- Don't over-apologize or self-flagellate\n- Move forward with better framing next time\n\n## Continuous Improvement\n\n### After Each Promotion Campaign\n- Which platforms drove best engagement?\n- What framing or angles worked best?\n- What relationships or opportunities emerged?\n- What would you do differently?\n- What follow-up content does this suggest?\n\n### Pattern Recognition\n- Which topics consistently resonate?\n- Which platforms are most effective for different content types?\n- How is your network evolving?\n- What themes are emerging in discussions?\n\n## Special Situations\n\n### Time-Sensitive Content\n- Prioritize platforms with fast engagement (Twitter, HN)\n- Consider posting at optimal times even if requires scheduling\n- Be prepared to engage actively in first few hours\n- Plan follow-up content if discussion takes off\n\n### Controversial Topics\n- Anticipate objections in initial framing\n- Be more careful with tone and precision\n- Prepare for more active engagement management\n- Consider which platforms can handle nuanced discussion\n\n### Technical Deep Dives\n- Prioritize platforms with technical audiences (HN, specific subreddits)\n- May skip or minimize less technical platforms\n- Expect slower but higher-quality engagement\n- Be prepared to answer detailed technical questions\n\n### Strategic/Business Content\n- LinkedIn becomes primary platform\n- Twitter/X good for reaching specific communities\n- Consider timing with business news cycles\n- Frame in terms of decisions and tradeoffs, not just analysis\n\n---\n\n## Using This Framework\n\n1. Provide the content URL and complete the Content Information Template\n2. Review my strategic brief and provide feedback\n3. Approve platforms and approaches\n4. Review and customize generated content\n5. Execute posting strategy\n6. Engage with responses using guidelines above\n7. Capture learnings for future campaigns\n\nThis framework is designed to be flexible\u2014adapt it based on what works for your specific goals and content. The key is maintaining authenticity while being strategic about how you share your work with the world.\n", "tokens": 693, "metadata": {"source_file": "runbooks/content-creation/content-promotion-framework.md", "category": "runbooks", "chunk_index": 4, "total_chunks": 5, "start_char": 12800, "end_char": 15573}}
{"id": "c1ba31880f32", "text": "# Universal Hyperlink Research Template\n\n## Purpose and Instructions\n\nThis template is designed to help you gather hyperlinks for blog posts, articles, presentations, or any content where you need to reference people, organizations, or other entities. You can use it in two ways:\n\n1. **Submit unmodified**: Submit this entire template as-is, and the AI will ask you for the names and entities you need links for\n2. **Fill in your needs**: Replace the example entries with your specific entities and their descriptions\n\nThe structure guides the AI to find the most authoritative and current links, prioritizing official websites over social media when appropriate.\n\n---\n\n# Hyperlink Research Request\n\nI need to find accurate hyperlinks for people, organizations, and entities mentioned in my content. Please help me locate the most authoritative and current links available.\n\n## People to Research\n\n[AI ASSISTANT NOTE: If no people are listed below this line, please ask the user which people they need links for. Otherwise, research the people listed.]\n\nExamples (replace with your people or leave as-is):\n- Person Name - Brief description of their role, affiliation, or why they're mentioned\n- Another Person - Notable achievements, position, or identifying details\n\n## Organizations and Entities\n\n[AI ASSISTANT NOTE: If no organizations are listed below this line, please ask the user which organizations they need links for. Otherwise, research the organizations listed.]\n\nExamples (replace with your organizations or leave as-is):\n- Organization Name - What they do, where they're based, or why they're relevant\n- Another Organization - Industry, significance, or distinguishing features\n\n## Link Prioritization\n\nFor people, please prioritize links in this order:\n1. Personal/professional website\n2. Institutional/company profile\n3. LinkedIn profile\n4. Other professional social media (Twitter/X, etc.)\n\nFor organizations, please prioritize:\n1. Official website\n2. Primary social media presence if no website exists\n3. Authoritative third-party profile (Wikipedia, Bloomberg, etc.) if no official presence exists\n\n## Required Output Format\n\nPlease provide the results in HTML format that I can easily copy-paste:\n\n```html\n<!-- People -->\n<a href=\"URL\">Person Name</a>\n<a href=\"URL\">Another Person</a>\n\n<!-- Organizations -->\n<a href=\"URL\">Organization Name</a>\n<a href=\"URL\">Another Organization</a>\n```\n\nIf you cannot find a link for any specific entity, please note that and suggest alternatives. For example: \"Could not find official page for X, consider linking to their LinkedIn profile or recent interview at [URL].\"\n\nFor especially common names or ambiguous entities, please confirm the context matches what I'm looking for before providing the final links.\n\nThank you for your help with this research task!\n\n---\n\n## Tips for Getting the Best Results\n\nWhen using this template, consider these recommendations:\n\n1. **Add context for ambiguous names**: For people with common names, include distinguishing details like their company, field of expertise, or location to ensure the correct person is identified.\n\n2. **Specify link recency**: If you need particularly current links, explicitly request the most recent official websites.\n\n3. **Request verification**: For particularly important links, ask the AI to provide a brief confirmation that the link is still active and matches the entity you're looking for.\n\n4. **Group related entities**: If you're writing about a specific industry or event, group your requests by category to help the AI understand the context better.\n\n5. **Regional preferences**: If you need links to region-specific versions of websites, mention this requirement explicitly.\n\n## Example Use Cases\n\nHere are some examples of how you might use this template:\n\n### For a Technology Conference Recap\n- Speakers: Several keynote speakers from various tech companies\n- Organizations: Conference host, sponsoring companies, featured startups\n\n### For an Industry Analys", "tokens": 1000, "metadata": {"source_file": "runbooks/content-creation/hyperlink-research.md", "category": "runbooks", "chunk_index": 0, "total_chunks": 2, "start_char": 0, "end_char": 4000}}
{"id": "eb7a5732607c", "text": "request the most recent official websites.\n\n3. **Request verification**: For particularly important links, ask the AI to provide a brief confirmation that the link is still active and matches the entity you're looking for.\n\n4. **Group related entities**: If you're writing about a specific industry or event, group your requests by category to help the AI understand the context better.\n\n5. **Regional preferences**: If you need links to region-specific versions of websites, mention this requirement explicitly.\n\n## Example Use Cases\n\nHere are some examples of how you might use this template:\n\n### For a Technology Conference Recap\n- Speakers: Several keynote speakers from various tech companies\n- Organizations: Conference host, sponsoring companies, featured startups\n\n### For an Industry Analysis\n- People: Key industry leaders, analysts, and innovators\n- Organizations: Major companies, regulatory bodies, research institutions\n\n### For Personal Research\n- People: Authors, researchers, or experts in your field of interest\n- Organizations: Universities, research centers, journals, or industry associations", "tokens": 278, "metadata": {"source_file": "runbooks/content-creation/hyperlink-research.md", "category": "runbooks", "chunk_index": 1, "total_chunks": 2, "start_char": 3200, "end_char": 4314}}
{"id": "192df35856d2", "text": "\n\n<instructions>\nPlease write social media posts for me. The posts must be written with the primary goal of accomplishing the purpose I have described here. Pay careful attention to all the instructions in this prompt. Before you write the posts, explain not only what my purpose and desired outcomes are, but improve on them. Then recap the instructions I have given you. Then show me your plan to meet my purpose, follow my instructions, and write the most effective social media posts for me. Finally, show me the posts you have written.\nThe instructions in the how-to-write and how-not-to-write sections only apply to the text of the social media posts you write for me, not to the rest of your response. For example, in answering my questions, you can be as verbose as you need to be.\n</instructions>\n\n<purpose>\n* Impress people who view this blog post without at all appearing like I am trying to impress them.\n* Make me look like an important, accomplished, sought-after person but in way that does not at all seem like that is what I am trying to accomplish.\n* Make me look like an expert and thought leader, especially in the field of Aritificial Intelligence without giving away that is what I am trying to do.\n</purpose>\n\n\n<event>\n\n<!-- The specific event or topic for the post. -->\n</event>\n\n<location>\nManhattan, New York City\n<!-- Optional: The location of the event. -->\n</location>\n\n<context>\n<!-- Key facts, details, and talking points about the event. -->\n</context>\n\n<tips>\n<!-- Specific guidance for this post, e.g., \"Mention the book name.\" -->\n</tips>\n\n<relevant-data>\nTwitter/X username: \nInstagram username: \n<!-- URLs, social media handles, etc. -->\n</relevant-data>\n\n\n<how-to-write>\n* Be concise\n* Only say things that are relevant\n* Write in a conversational voice\n* Appear authentic and genuine\n* Sound sincere\n* Share insights. Show that I'm insightful\n* Please display the URL link in your output because LinkedIn and Twitter do not yet support copying and pasting rich text into their text areas for posting.\n</how-to-write>\n\n<how-not-to-write>\n* Do not brag\n* Do not humble brag\n* Do not sound obsequious\n* Do not seem to be star struck. Do not put myself down nor make others look more important than me\n* Do not say things like I was \"honored\", \"privileged\" that sound obsequious or humble bragging\n* Do not be verbose\n* Do not state the obvious\n* Do not write in marketing-speak\n* Do not use grandiose adjectives or adverbs that add no or little value. \n* Do not write in a way that seems like I am showing off, trying too hard, or seem desperate.\n* Hashtags often give the impression that the post is not speaking from the heart, but is written to maximize reach. Avoid using hashtags, unless they avoid this problem. If you determine to use hashtags, please include a few highly relevant hashtags at the end.\n* Use @ mentions of people's names at the end of the post, but in the main body of the post, write their names like a human would\n<how-not-to-write>\n\n\n<social-platforms>\nPlease write versions of the social media post for\n* Twitter/X\n* Instagram\n* LinkedIn\n<!-- List the platforms for which to generate content. -->\n</social-platforms>\n\n", "tokens": 795, "metadata": {"source_file": "runbooks/content-creation/social-media-post.md", "category": "runbooks", "chunk_index": 0, "total_chunks": 1, "start_char": 0, "end_char": 3182}}
{"id": "df3038d460a8", "text": "# Advanced Blog Post Revitalization Framework\n\nI'm seeking to revitalize one of my blog posts while preserving its historical integrity and ensuring it appears to have been written entirely on its original publication date. This enhanced version should feel like the post I would have written if I had more time, deeper insights, and clearer vision on that original day.\n\n## Initial Information Required\n\n[If you don't have this information already, please ask me for:]\n- The URL of the blog post (contains the publication date)\n- The complete original content (either pasted directly or uploaded as a file with formatting preserved)\n- Any supporting materials (PDF of full web page, markdown with hyperlinks preserved)\n- Context about the original post's purpose, target audience, or performance metrics (if available)\n- Any specific areas of concern or goals for the enhancement\n\n## Core Objective\n\nTransform my blog post into its optimal version\u2014what it could have been with perfect clarity, complete information available at the time, and ideal execution\u2014while maintaining absolute temporal authenticity. The enhanced post should represent the crystallization of my best thinking on that date, as if I had achieved perfect insight and expression in the original moment.\n\n## Deep Analysis Framework\n\n### Content Architecture Analysis\n1. **Core Value Proposition**: What unique insight or value does this post attempt to deliver?\n2. **Audience Alignment**: Who was the intended reader, and how well does the content serve them?\n3. **Argument Structure**: How effectively does the post build and support its main points?\n4. **Knowledge Gaps**: What relevant information (available at the time) is missing?\n5. **Emotional Journey**: What feeling or transformation should the reader experience?\n\n### Voice and Style Profile\n1. **Distinctive Elements**: Identify specific phrases, patterns, or techniques that define my voice\n2. **Rhetorical Devices**: Note my use of metaphors, analogies, questions, or other devices\n3. **Technical Register**: Assess the level of technical detail and jargon usage\n4. **Personal Elements**: Identify how I incorporate personal experiences or perspectives\n5. **Engagement Techniques**: How do I typically connect with and involve readers?\n\n### Temporal Context Assessment\n1. **Industry Climate**: What was happening in the relevant field at publication time?\n2. **Technology Landscape**: What tools, platforms, and capabilities existed?\n3. **Cultural Zeitgeist**: What broader trends or conversations were occurring?\n4. **Knowledge Frontier**: What was cutting-edge versus established wisdom?\n5. **Future Trajectory**: What predictions or trends would have seemed reasonable?\n\n## Enhancement Strategies (Apply Based on Deep Analysis)\n\n### Content Sophistication Techniques\n\n#### Conceptual Development\n- **Depth Expansion**: Develop ideas to their natural conclusion rather than leaving them partially explored\n- **Nuance Addition**: Introduce appropriate caveats, edge cases, and contextual factors\n- **Framework Creation**: Build memorable mental models that help readers apply concepts\n- **Interconnection**: Draw connections between ideas that enhance understanding\n- **Abstraction Laddering**: Move between concrete examples and abstract principles effectively\n\n#### Evidence and Support\n- **Case Study Integration**: Add period-appropriate examples that illustrate key points\n- **Data Enhancement**: Include statistics or research available at publication time\n- **Expert Perspectives**: Reference thought leaders or research from that era\n- **Counterargument Addressing**: Acknowledge and respond to likely objections\n- **Validation Methods**: Suggest ways readers could verify or test ideas\n\n### Structural Excellence Options\n\n#### Information Architecture\n- **Cognitive Load Management**: Organize information to minimize reader effort\n- **Progressive Disclosure**: Layer complexity appropriately throughout the post\n- **Conceptual Scaffolding**: Build underst", "tokens": 1000, "metadata": {"source_file": "runbooks/content-enhancement/blog-revitalization-framework.md", "category": "runbooks", "chunk_index": 0, "total_chunks": 4, "start_char": 0, "end_char": 4000}}
{"id": "d66d2843446c", "text": "\n- **Abstraction Laddering**: Move between concrete examples and abstract principles effectively\n\n#### Evidence and Support\n- **Case Study Integration**: Add period-appropriate examples that illustrate key points\n- **Data Enhancement**: Include statistics or research available at publication time\n- **Expert Perspectives**: Reference thought leaders or research from that era\n- **Counterargument Addressing**: Acknowledge and respond to likely objections\n- **Validation Methods**: Suggest ways readers could verify or test ideas\n\n### Structural Excellence Options\n\n#### Information Architecture\n- **Cognitive Load Management**: Organize information to minimize reader effort\n- **Progressive Disclosure**: Layer complexity appropriately throughout the post\n- **Conceptual Scaffolding**: Build understanding step-by-step\n- **Strategic Redundancy**: Reinforce key concepts without being repetitive\n- **Navigation Aids**: Create clear pathways through complex topics\n\n#### Narrative Flow\n- **Hook Development**: Craft compelling openings that establish stakes\n- **Tension and Resolution**: Create intellectual or emotional journey arcs\n- **Momentum Maintenance**: Ensure each section propels readers forward\n- **Callback Integration**: Reference earlier points to create cohesion\n- **Memorable Conclusions**: End with insights that resonate beyond reading\n\n### Reader Experience Optimization\n\n#### Engagement Techniques\n- **Interactive Elements**: Pose questions or challenges for reader reflection\n- **Visualization Aids**: Describe concepts in ways that create mental images\n- **Relatability Bridges**: Connect abstract ideas to common experiences\n- **Curiosity Gaps**: Create and strategically resolve knowledge gaps\n- **Emotional Resonance**: Align content with reader motivations and concerns\n\n#### Clarity Enhancement\n- **Jargon Translation**: Provide accessible explanations for technical terms\n- **Concept Chunking**: Break complex ideas into digestible components\n- **Transition Crafting**: Create smooth connections between ideas\n- **Emphasis Hierarchy**: Use formatting to guide attention appropriately\n- **Redundancy Elimination**: Remove repetitive or tangential content\n\n### Period-Appropriate SEO and Discoverability\n\n#### Organic Optimization\n- **Natural Keyword Integration**: Include terms people would have searched for then\n- **Semantic Richness**: Use varied terminology that search engines of the era would recognize\n- **Title and Header Optimization**: Craft compelling, search-friendly headings\n- **Meta Description Worthy**: Ensure opening paragraphs work as effective previews\n- **Internal Linking**: Reference other relevant posts or resources appropriately\n\n## Advanced Temporal Integrity Protocols\n\n### Chronological Consistency Checks\n- **Technology References**: Verify all mentioned tools/platforms existed and were accessible\n- **Cultural References**: Ensure examples and metaphors align with the zeitgeist\n- **Knowledge Boundaries**: Respect what was known versus speculative at the time\n- **Terminology Evolution**: Use period-appropriate language and avoid anachronisms\n- **Prediction Calibration**: Ensure any forward-looking statements seem reasonable for the era\n\n### Subtle Temporal Markers\n- **Contemporary Concerns**: Reference challenges or opportunities relevant to that moment\n- **Period-Specific Phrasing**: Use expressions and idioms common to that time\n- **Technology Assumptions**: Reflect the capabilities and limitations of the era\n- **Cultural Touchstones**: Reference events or trends that anchor the time period\n- **Future Framing**: Discuss upcoming developments as appropriately uncertain\n\n## Style Authenticity Preservation\n\n### Voice Consistency Framework\n1. **Lexical Fingerprinting**: Maintain vocabulary patterns and word choice preferences\n2. **Syntactic Signatures**: Preserve sentence structure and rhythm patterns\n3. **Rhetorical DNA**: Keep characteristic persuasion and explanation techniques\n4. **Personality Markers**: Maintain humor", "tokens": 1000, "metadata": {"source_file": "runbooks/content-enhancement/blog-revitalization-framework.md", "category": "runbooks", "chunk_index": 1, "total_chunks": 4, "start_char": 3200, "end_char": 7200}}
{"id": "d737c3fb801b", "text": "\n### Subtle Temporal Markers\n- **Contemporary Concerns**: Reference challenges or opportunities relevant to that moment\n- **Period-Specific Phrasing**: Use expressions and idioms common to that time\n- **Technology Assumptions**: Reflect the capabilities and limitations of the era\n- **Cultural Touchstones**: Reference events or trends that anchor the time period\n- **Future Framing**: Discuss upcoming developments as appropriately uncertain\n\n## Style Authenticity Preservation\n\n### Voice Consistency Framework\n1. **Lexical Fingerprinting**: Maintain vocabulary patterns and word choice preferences\n2. **Syntactic Signatures**: Preserve sentence structure and rhythm patterns\n3. **Rhetorical DNA**: Keep characteristic persuasion and explanation techniques\n4. **Personality Markers**: Maintain humor, formality, or other tonal elements\n5. **Expertise Indicators**: Preserve the way you demonstrate knowledge and authority\n\n### Enhancement Integration Principles\n- **Seamless Blending**: New content should be indistinguishable from original\n- **Style-Appropriate Improvements**: Enhance in ways consistent with your voice\n- **Natural Evolution**: Allow for subtle growth within your established style\n- **Characteristic Preservation**: Maintain quirks or unique elements that define you\n- **Coherence Maintenance**: Ensure the entire post feels unified\n\n## Natural Variation and Authenticity\n\n### Organic Enhancement Patterns\n1. **Variable Depth**: Some sections naturally deserve more development than others\n2. **Rhythm Variation**: Mix analytical sections with narrative or practical elements\n3. **Energy Fluctuation**: Allow for natural peaks and valleys in intensity\n4. **Focus Shifting**: Move between broad concepts and specific details organically\n5. **Voice Modulation**: Let tone shift appropriately with content needs\n\n### Anti-Pattern Avoidance\n- **Formula Resistance**: Avoid applying the same structure to every post\n- **Over-Optimization**: Maintain some natural imperfections for authenticity\n- **Mechanical Transitions**: Ensure connections feel natural, not templated\n- **Excessive Polish**: Preserve some rough edges that indicate human authorship\n- **Uniformity Traps**: Vary paragraph lengths, section sizes, and example types\n\n## Quality Evaluation Metrics\n\n### Content Excellence Indicators\n- **Value Density**: How much useful insight per paragraph?\n- **Clarity Score**: How easily can target readers understand key concepts?\n- **Actionability**: Can readers apply what they've learned?\n- **Memorability**: Will key insights stick with readers?\n- **Differentiation**: Does this offer unique value versus other content?\n\n### Authenticity Verification\n- **Voice Consistency**: Does it sound like me throughout?\n- **Temporal Accuracy**: Could this have been written on the original date?\n- **Natural Flow**: Does it read like organic human writing?\n- **Style Coherence**: Do enhancements blend seamlessly?\n- **Purpose Alignment**: Does it achieve the original post's goals better?\n\n## Implementation Process\n\n### Phase 1: Deep Understanding\n1. Read the original post multiple times, noting strengths and weaknesses\n2. Research the temporal context and available knowledge at publication\n3. Identify the core value proposition and target audience\n4. Map your voice characteristics and style patterns\n5. Determine which enhancement strategies will provide maximum value\n\n### Phase 2: Strategic Enhancement\n1. Develop a customized enhancement plan based on analysis\n2. Apply improvements iteratively, maintaining temporal integrity\n3. Ensure each addition strengthens rather than dilutes the message\n4. Balance depth with readability and engagement\n5. Integrate enhancements naturally with existing content\n\n### Phase 3: Refinement and Verification\n1. Review for temporal consistency and authenticity\n2. Ensure voice and style remain consistent throughout\n3. Verify all facts, examples, and references are period-appropriate\n4. Check that the enhanced version fulfills the original", "tokens": 1000, "metadata": {"source_file": "runbooks/content-enhancement/blog-revitalization-framework.md", "category": "runbooks", "chunk_index": 2, "total_chunks": 4, "start_char": 6400, "end_char": 10400}}
{"id": "a72fa0a44888", "text": "lication\n3. Identify the core value proposition and target audience\n4. Map your voice characteristics and style patterns\n5. Determine which enhancement strategies will provide maximum value\n\n### Phase 2: Strategic Enhancement\n1. Develop a customized enhancement plan based on analysis\n2. Apply improvements iteratively, maintaining temporal integrity\n3. Ensure each addition strengthens rather than dilutes the message\n4. Balance depth with readability and engagement\n5. Integrate enhancements naturally with existing content\n\n### Phase 3: Refinement and Verification\n1. Review for temporal consistency and authenticity\n2. Ensure voice and style remain consistent throughout\n3. Verify all facts, examples, and references are period-appropriate\n4. Check that the enhanced version fulfills the original's promise better\n5. Polish for natural flow and compelling reader experience\n\n## Final Quality Assurance\n\nThe revitalized post must:\n- Deliver significantly more value while maintaining the original's essence\n- Read as if you had perfect clarity and unlimited time on the original date\n- Maintain absolute temporal integrity with no anachronisms\n- Preserve and amplify your unique voice and perspective\n- Feel like a natural, organic piece of writing, not an artificial enhancement\n- Serve the original audience better while potentially appealing to a broader readership\n- Stand as the definitive version of your thoughts on this topic from that moment in time\n- Include all valuable hyperlinks from the original (unless deliberately removed for good reason)\n- Create a lasting resource that remains valuable beyond its publication date\n", "tokens": 409, "metadata": {"source_file": "runbooks/content-enhancement/blog-revitalization-framework.md", "category": "runbooks", "chunk_index": 3, "total_chunks": 4, "start_char": 9600, "end_char": 11238}}
{"id": "dd2857b1724d", "text": "# Historical Blog Post Revitalization Prompt\n\nPlease revitalize the attached blog post using the Advanced Blog Post Revitalization Framework (also attached). Create an enhanced version that significantly improves value, clarity, and reader engagement while maintaining absolute temporal integrity\u2014the post must appear to have been written entirely on its original publication date.\n\nIf the blog post URL isn't included in the attachments, it is: [INSERT URL IF NEEDED]\n\nPlease provide the complete enhanced post that represents what I could have written with perfect insight and execution on that original date.\n\nPlease create a document artifact containing the revitalized blog post.\n", "tokens": 171, "metadata": {"source_file": "runbooks/content-enhancement/blog-revitalization-prompt.md", "category": "runbooks", "chunk_index": 0, "total_chunks": 1, "start_char": 0, "end_char": 685}}
{"id": "f9e6042b958f", "text": "# Enterprise-Grade Codebase Review Runbook\n\n> **Version**: 2.0  \n> **Author**: Personal Pant  \n> **Purpose**: Comprehensive, practical codebase audit for projects of any size  \n> **Usage**: Use with Claude Code, Cursor, or any AI-assisted development environment  \n> **License**: Open source under MIT License  \n> **Repository**: Part of the [Ragbot.AI](https://ragbot.ai) project  \n> **Methodology**: Based on [Synthesis Coding](https://synthesiscoding.com) principles\n\n---\n\n## HOW TO USE THIS RUNBOOK\n\nThis runbook is designed to be **both comprehensive AND practical**. Not every project needs every check. \n\n### Step 1: Assess Your Project Tier\n\nStart by completing the **Project Complexity Assessment** below. This determines which tier your project falls into and which sections apply.\n\n### Step 2: Review Applicable Sections\n\nEach section and many individual items are marked with tier indicators:\n- \ud83d\udfe2 **Essential** (Tier 1) - Apply to ALL projects, even weekend hacks\n- \ud83d\udd35 **Standard** (Tier 2) - Apply to team projects and production apps  \n- \ud83d\udfe3 **Enterprise** (Tier 3) - Apply to large-scale, multi-team, or regulated systems\n- \u26ab **Mission-Critical** (Tier 4) - Apply to financial, healthcare, infrastructure, or high-stakes systems\n\n### Step 3: Skip What Doesn't Apply\n\n- If you're Tier 1, focus only on \ud83d\udfe2 items (~50 checks)\n- If you're Tier 2, include \ud83d\udfe2 and \ud83d\udd35 items (~150 checks)\n- If you're Tier 3, include \ud83d\udfe2, \ud83d\udd35, and \ud83d\udfe3 items (~400 checks)\n- If you're Tier 4, include everything (~900+ checks)\n\n### Step 4: Use the Quick Start (Optional)\n\nIf you want a rapid assessment, use the **Minimum Viable Review** section for a 15-minute health check.\n\n---\n\n## PROJECT COMPLEXITY ASSESSMENT\n\n> Complete this assessment first to determine your project tier.\n\n### Project Characteristics\n\nScore each characteristic (0 = No, 1 = Yes):\n\n**Scale & Users**\n| Question | Score |\n|----------|-------|\n| Does the project have >1 developer? | |\n| Does the project have >5 developers? | |\n| Does the project have >20 developers? | |\n| Will there be >100 users? | |\n| Will there be >10,000 users? | |\n| Will there be >1,000,000 users? | |\n\n**Business Criticality**\n| Question | Score |\n|----------|-------|\n| Is this a production system (not a prototype/experiment)? | |\n| Would downtime cost money directly? | |\n| Would downtime cost >$10,000/hour? | |\n| Would a security breach make the news? | |\n| Are there contractual SLAs? | |\n\n**Data Sensitivity**\n| Question | Score |\n|----------|-------|\n| Does the system handle user accounts? | |\n| Does the system handle PII (names, emails, addresses)? | |\n| Does the system handle financial data (payments, banking)? | |\n| Does the system handle health data (PHI/HIPAA)? | |\n| Does the system handle data subject to regulations (GDPR, SOX, etc.)? | |\n\n**Architecture Complexity**\n| Question | Score |\n|----------|-------|\n| Is there more than one deployable service? | |\n| Are there more than 5 services? | |\n| Is there a database? | |\n| Are there multiple databases or data stores? | |\n| Are there third-party integrations? | |\n| Are there more than 5 third-party integrations? | |\n\n**Operational Requirements**\n| Question | Score |\n|----------|-------|\n| Is 99% uptime required? | |\n| Is 99.9% uptime required? | |\n| Is 99.99% uptime required? | |\n| Is there a dedicated ops/SRE team? | |\n| Is there 24/7 on-call? | |\n\n### Calculate Your Tier\n\n**Total Score: ____**\n\n| Score Range | Tier | Description |\n|-------------|------|-------------|\n| 0-4 | **Tier 1 - Essential** \ud83d\udfe2 | Solo/hobby projects, prototypes, internal tools |\n| 5-10 | **Tier 2 - Standard** \ud83d\udd35 | Small team projects, production apps, startups |\n| 11-18 | **Tier 3 - Enterprise** \ud83d\udfe3 | Large teams, regulated industries, enterprise customers |\n| 19+ | **Tier 4 - Mission-Critical** \u26ab | Financial systems, healthcare, critical infrastructure |\n\n**Your Tier: ____**\n\n---\n\n## MINIMUM VIABLE REVIEW (15-Minute Quick Check)\n\n> Use this for a rapid health assessment. These are the absolute essentials that app", "tokens": 1000, "metadata": {"source_file": "runbooks/engineering/codebase-review.md", "category": "runbooks", "chunk_index": 0, "total_chunks": 12, "start_char": 0, "end_char": 4000}}
{"id": "442fa1b29a48", "text": "me required? | |\n| Is 99.9% uptime required? | |\n| Is 99.99% uptime required? | |\n| Is there a dedicated ops/SRE team? | |\n| Is there 24/7 on-call? | |\n\n### Calculate Your Tier\n\n**Total Score: ____**\n\n| Score Range | Tier | Description |\n|-------------|------|-------------|\n| 0-4 | **Tier 1 - Essential** \ud83d\udfe2 | Solo/hobby projects, prototypes, internal tools |\n| 5-10 | **Tier 2 - Standard** \ud83d\udd35 | Small team projects, production apps, startups |\n| 11-18 | **Tier 3 - Enterprise** \ud83d\udfe3 | Large teams, regulated industries, enterprise customers |\n| 19+ | **Tier 4 - Mission-Critical** \u26ab | Financial systems, healthcare, critical infrastructure |\n\n**Your Tier: ____**\n\n---\n\n## MINIMUM VIABLE REVIEW (15-Minute Quick Check)\n\n> Use this for a rapid health assessment. These are the absolute essentials that apply to ANY project.\n\n### \ud83d\udfe2 Security Essentials (5 minutes)\n- [ ] **No secrets in code**: Run `git log -p | grep -i \"password\\|secret\\|api_key\\|token\"` - should return nothing\n- [ ] **Dependencies not ancient**: Check for critical vulnerabilities (`npm audit`, `pip-audit`, etc.)\n- [ ] **HTTPS only**: All external communication uses TLS\n- [ ] **Input validated**: User input is validated before use\n- [ ] **Auth exists**: If there are users, authentication is implemented properly\n\n### \ud83d\udfe2 Code Health (5 minutes)\n- [ ] **It builds**: Clean build with no errors\n- [ ] **Tests exist**: There are some automated tests\n- [ ] **Tests pass**: All tests pass\n- [ ] **No obvious duplication**: No copy-pasted files or massive repeated blocks\n- [ ] **Readable**: A new developer could understand the main flow\n\n### \ud83d\udfe2 Operations Essentials (5 minutes)\n- [ ] **README exists**: There's documentation on how to run it\n- [ ] **Can be deployed**: There's a documented or automated deployment process\n- [ ] **Logs exist**: The application produces logs\n- [ ] **Errors tracked**: Errors are logged or sent somewhere visible\n- [ ] **Config externalized**: No hardcoded environment-specific values\n\n**Quick Score: ____ / 15**\n\nIf you score <12, address the gaps before proceeding. If you score 12+, continue to the full review based on your tier.\n\n---\n\n## CUSTOMIZATION SECTION\n\n> Customize these settings before running the full review.\n\n### Organization Context\n\n```yaml\norganization_name: \"[Your Organization]\"\nproject_tier: \"[1-Essential | 2-Standard | 3-Enterprise | 4-Mission-Critical]\"\nindustry: \"[e.g., Financial Services, Healthcare, Media, E-commerce, SaaS, Open Source]\"\ncodebase_name: \"[Project/Product Name]\"\nprimary_language: \"[e.g., Python, TypeScript, Go, Java]\"\nframework: \"[e.g., Django, Next.js, Spring Boot]\"\ndeployment_target: \"[e.g., AWS, GCP, Azure, On-premise, Hybrid]\"\nis_open_source: \"[yes | no]\"\n```\n\n### Compliance Requirements (Tier 3-4)\n\n> Check all that apply to your organization:\n\n- [ ] SOC 2 Type II\n- [ ] GDPR\n- [ ] CCPA/CPRA\n- [ ] HIPAA\n- [ ] PCI-DSS\n- [ ] FedRAMP\n- [ ] ISO 27001\n- [ ] NIST Cybersecurity Framework\n- [ ] WCAG 2.1 AA (Accessibility)\n- [ ] Industry-specific: ________________\n\n### Review Scope\n\n```yaml\nreview_type: \"[full | security-focused | scalability-focused | pre-launch]\"\npriority_areas: \"[comma-separated list of focus areas]\"\nexcluded_paths: \"[paths to exclude from review, e.g., vendor/, generated/]\"\n```\n\n---\n\n## MAIN REVIEW PROMPT\n\nYou are conducting a codebase review using the Enterprise-Grade Codebase Review Runbook. \n\n**Project Tier: [INSERT TIER]**\n\nReview ONLY the sections marked for this tier or lower:\n- Tier 1 (\ud83d\udfe2): Review only \ud83d\udfe2 items\n- Tier 2 (\ud83d\udd35): Review \ud83d\udfe2 and \ud83d\udd35 items\n- Tier 3 (\ud83d\udfe3): Review \ud83d\udfe2, \ud83d\udd35, and \ud83d\udfe3 items\n- Tier 4 (\u26ab): Review all items\n\nFor each finding, document:\n1. Specific file paths and line numbers\n2. Severity (Critical/High/Medium/Low)\n3. Concrete remediation steps\n\n---\n\n## 1. ARCHITECTURE & SYSTEM DESIGN\n\n### 1.1 Architectural Foundation\n\n- [ ] \ud83d\udfe2 **Code Organization**: Is there a logical folder/module structure?\n- [ ] \ud83d\udfe2 **Separation of Concerns**: Is business logic separated from I/O and presentation?\n- [ ] \ud83d\udd35 **Pattern Identif", "tokens": 1000, "metadata": {"source_file": "runbooks/engineering/codebase-review.md", "category": "runbooks", "chunk_index": 1, "total_chunks": 12, "start_char": 3200, "end_char": 7200}}
{"id": "40681e684292", "text": "e from review, e.g., vendor/, generated/]\"\n```\n\n---\n\n## MAIN REVIEW PROMPT\n\nYou are conducting a codebase review using the Enterprise-Grade Codebase Review Runbook. \n\n**Project Tier: [INSERT TIER]**\n\nReview ONLY the sections marked for this tier or lower:\n- Tier 1 (\ud83d\udfe2): Review only \ud83d\udfe2 items\n- Tier 2 (\ud83d\udd35): Review \ud83d\udfe2 and \ud83d\udd35 items\n- Tier 3 (\ud83d\udfe3): Review \ud83d\udfe2, \ud83d\udd35, and \ud83d\udfe3 items\n- Tier 4 (\u26ab): Review all items\n\nFor each finding, document:\n1. Specific file paths and line numbers\n2. Severity (Critical/High/Medium/Low)\n3. Concrete remediation steps\n\n---\n\n## 1. ARCHITECTURE & SYSTEM DESIGN\n\n### 1.1 Architectural Foundation\n\n- [ ] \ud83d\udfe2 **Code Organization**: Is there a logical folder/module structure?\n- [ ] \ud83d\udfe2 **Separation of Concerns**: Is business logic separated from I/O and presentation?\n- [ ] \ud83d\udd35 **Pattern Identification**: What architectural pattern is implemented (MVC, microservices, modular monolith, etc.)?\n- [ ] \ud83d\udd35 **Pattern Appropriateness**: Is the chosen architecture suitable for the scale and team size?\n- [ ] \ud83d\udfe3 **Architecture Documentation**: Is there an Architecture Decision Record (ADR)?\n- [ ] \ud83d\udfe3 **Dependency Graph**: Are there circular dependencies between modules/services?\n- [ ] \ud83d\udfe3 **Domain Boundaries**: Are bounded contexts clearly defined?\n- [ ] \u26ab **Layer Separation**: Is there strict separation between layers with enforced boundaries?\n\n### 1.2 API Design & Contracts\n\n- [ ] \ud83d\udfe2 **Consistent Endpoints**: Are API endpoints named consistently?\n- [ ] \ud83d\udd35 **API Documentation**: Is there basic API documentation (README, comments, or OpenAPI)?\n- [ ] \ud83d\udd35 **Error Format Consistency**: Are error responses formatted consistently?\n- [ ] \ud83d\udfe3 **API Versioning**: Are APIs versioned?\n- [ ] \ud83d\udfe3 **Contract Documentation**: Is there OpenAPI/Swagger or GraphQL schema?\n- [ ] \ud83d\udfe3 **Deprecation Strategy**: Is there a documented process for deprecating APIs?\n- [ ] \u26ab **API Gateway**: Is there proper gateway implementation with routing, auth, rate limiting?\n- [ ] \u26ab **Contract Testing**: Are API contracts tested for backward compatibility?\n\n### 1.3 Service Communication (Tier 3+)\n\n- [ ] \ud83d\udfe3 **Sync vs Async**: Are synchronous and asynchronous patterns used appropriately?\n- [ ] \ud83d\udfe3 **Timeout Configuration**: Are timeouts configured for all network calls?\n- [ ] \ud83d\udfe3 **Resilience Patterns**: Are circuit breakers and retries implemented?\n- [ ] \u26ab **Message Contracts**: For event-driven systems, are message schemas versioned?\n- [ ] \u26ab **Service Discovery**: How do services find each other? Is it robust?\n- [ ] \u26ab **Data Consistency**: How is eventual consistency handled across services?\n\n### 1.4 Data Architecture\n\n- [ ] \ud83d\udfe2 **Data Store Exists**: Is there a proper database (not just files)?\n- [ ] \ud83d\udd35 **Schema Design**: Is the database schema reasonably normalized?\n- [ ] \ud83d\udd35 **Indexes Present**: Are there indexes on frequently queried columns?\n- [ ] \ud83d\udfe3 **Data Store Selection**: Are the right databases used for the right purposes?\n- [ ] \ud83d\udfe3 **Caching Strategy**: Is there a caching strategy?\n- [ ] \u26ab **Data Flow Documentation**: Is data flow through the system documented?\n\n---\n\n## 2. SECRETS, CREDENTIALS & SENSITIVE DATA\n\n> **\ud83d\udd34 This section is CRITICAL for all tiers.** Secrets in code are one of the most common and dangerous vulnerabilities.\n\n### 2.1 Active Secret Scanning \ud83d\udfe2\n\n- [ ] \ud83d\udfe2 **No Hardcoded Secrets**: Search for passwords, API keys, tokens in code\n- [ ] \ud83d\udfe2 **Environment Files Not Committed**: `.env` files are in `.gitignore`\n- [ ] \ud83d\udd35 **Secret Scanner Run**: Run tools like `truffleHog`, `gitleaks`, or `detect-secrets`\n- [ ] \ud83d\udfe3 **Git History Clean**: No secrets in git history (even if removed from current code)\n- [ ] \ud83d\udfe3 **CI/CD Configs Clean**: No secrets in workflow files, Dockerfiles, or IaC\n\n### 2.2 Secret Types to Search For \ud83d\udfe2\n\n- [ ] \ud83d\udfe2 Passwords and passphrases\n- [ ] \ud83d\udfe2 API keys (AWS, GCP, Stripe, etc.)\n- [ ] \ud83d\udfe2 Database connection strings with credentials\n- [ ] \ud83d\udd35 Private keys (RSA, SSH, PGP)\n- [ ] \ud83d\udd35 OAuth client secrets\n- [ ] \ud83d\udd35 JWT signing secrets\n- [ ] \ud83d\udfe3 Encryption keys and salts\n- [ ] \ud83d\udfe3 Webhook secret", "tokens": 1000, "metadata": {"source_file": "runbooks/engineering/codebase-review.md", "category": "runbooks", "chunk_index": 2, "total_chunks": 12, "start_char": 6400, "end_char": 10400}}
{"id": "85e43ebb77ac", "text": "s vulnerabilities.\n\n### 2.1 Active Secret Scanning \ud83d\udfe2\n\n- [ ] \ud83d\udfe2 **No Hardcoded Secrets**: Search for passwords, API keys, tokens in code\n- [ ] \ud83d\udfe2 **Environment Files Not Committed**: `.env` files are in `.gitignore`\n- [ ] \ud83d\udd35 **Secret Scanner Run**: Run tools like `truffleHog`, `gitleaks`, or `detect-secrets`\n- [ ] \ud83d\udfe3 **Git History Clean**: No secrets in git history (even if removed from current code)\n- [ ] \ud83d\udfe3 **CI/CD Configs Clean**: No secrets in workflow files, Dockerfiles, or IaC\n\n### 2.2 Secret Types to Search For \ud83d\udfe2\n\n- [ ] \ud83d\udfe2 Passwords and passphrases\n- [ ] \ud83d\udfe2 API keys (AWS, GCP, Stripe, etc.)\n- [ ] \ud83d\udfe2 Database connection strings with credentials\n- [ ] \ud83d\udd35 Private keys (RSA, SSH, PGP)\n- [ ] \ud83d\udd35 OAuth client secrets\n- [ ] \ud83d\udd35 JWT signing secrets\n- [ ] \ud83d\udfe3 Encryption keys and salts\n- [ ] \ud83d\udfe3 Webhook secrets\n- [ ] \ud83d\udfe3 Service account credentials\n\n### 2.3 Secret Management \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Environment Variables**: Secrets loaded from environment variables\n- [ ] \ud83d\udd35 **Not in Logs**: Secrets are not logged\n- [ ] \ud83d\udfe3 **Secrets Manager**: Using Vault, AWS Secrets Manager, or equivalent\n- [ ] \ud83d\udfe3 **Secret Rotation**: Secrets can be rotated without code changes\n- [ ] \u26ab **Secret Access Audit**: Access to secrets is logged\n- [ ] \u26ab **Least Privilege**: Services only access secrets they need\n\n### 2.4 Preventive Controls \ud83d\udd35\n\n- [ ] \ud83d\udd35 **`.gitignore` Coverage**: Sensitive file patterns in `.gitignore`\n- [ ] \ud83d\udfe3 **Pre-Commit Hooks**: Hooks to prevent secret commits\n- [ ] \ud83d\udfe3 **CI/CD Scanning**: Secret scanning in the pipeline\n- [ ] \u26ab **PR Checks**: Automated PR checks for secrets\n\n---\n\n## 3. CODE DUPLICATION & REUSABILITY\n\n### 3.1 Duplication Analysis \ud83d\udd35\n\n- [ ] \ud83d\udd35 **No Copied Files**: No nearly-identical files\n- [ ] \ud83d\udd35 **No Large Repeated Blocks**: No blocks of 20+ lines repeated\n- [ ] \ud83d\udfe3 **Duplication Scanner Run**: Run jscpd, PMD CPD, or SonarQube\n- [ ] \ud83d\udfe3 **Duplication Under 5%**: Total duplication is under 5% of codebase\n- [ ] \u26ab **Cross-Module Duplication**: No significant duplication across services\n\n### 3.2 Shared Code & Libraries \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Utility Functions Centralized**: Common utilities in one place\n- [ ] \ud83d\udd35 **No Copy-Paste Coding**: Similar problems solved the same way\n- [ ] \ud83d\udfe3 **Internal Libraries**: Shared code in proper internal packages\n- [ ] \ud83d\udfe3 **Library Versioning**: Internal packages are versioned\n- [ ] \u26ab **Library Documentation**: Shared libraries are documented\n\n### 3.3 Abstraction Quality \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **Appropriate Abstraction**: Not over-abstracted or under-abstracted\n- [ ] \ud83d\udfe3 **DRY Applied Sensibly**: DRY used where it reduces complexity\n- [ ] \ud83d\udfe3 **Rule of Three**: Abstraction after 3+ occurrences\n- [ ] \u26ab **Cross-Cutting Concerns**: Logging, auth, validation handled consistently\n\n---\n\n## 4. CODE QUALITY, EFFICIENCY & OPTIMIZATION\n\n### 4.1 Basic Code Quality \ud83d\udfe2\n\n- [ ] \ud83d\udfe2 **No Obvious Bugs**: No clearly broken code paths\n- [ ] \ud83d\udfe2 **No Dead Code**: No large blocks of commented-out or unreachable code\n- [ ] \ud83d\udfe2 **Reasonable Function Size**: Functions generally under 50 lines\n- [ ] \ud83d\udd35 **Consistent Style**: Code style is consistent throughout\n- [ ] \ud83d\udd35 **Linting Passes**: Linting configured and passing\n\n### 4.2 Algorithmic Efficiency \ud83d\udd35\n\n- [ ] \ud83d\udd35 **No O(n\u00b2) in Hot Paths**: No nested loops over large collections\n- [ ] \ud83d\udd35 **Appropriate Data Structures**: Using maps/sets instead of array searches\n- [ ] \ud83d\udfe3 **Hot Path Optimization**: Performance-critical paths identified and optimized\n- [ ] \u26ab **Complexity Documented**: Complex algorithms have documented complexity\n\n### 4.3 Database Efficiency \ud83d\udd35\n\n- [ ] \ud83d\udd35 **No N+1 Queries**: No loops that execute queries\n- [ ] \ud83d\udd35 **Pagination**: Large datasets are paginated\n- [ ] \ud83d\udfe3 **Indexes Appropriate**: Queries use indexes effectively\n- [ ] \ud83d\udfe3 **Connection Pooling**: Database connections are pooled\n- [ ] \u26ab **Query Analysis**: Slow queries identified and optimized\n\n### 4.4 Memory & Resource Efficiency \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **No Memory Leaks**: Event listeners removed, no circular references\n- [ ] \ud83d\udfe3 **Streaming for Large Data**: Large files/datasets streamed\n- [ ] \ud83d\udfe3 ", "tokens": 1000, "metadata": {"source_file": "runbooks/engineering/codebase-review.md", "category": "runbooks", "chunk_index": 3, "total_chunks": 12, "start_char": 9600, "end_char": 13600}}
{"id": "fd6521d6d7d9", "text": "arge collections\n- [ ] \ud83d\udd35 **Appropriate Data Structures**: Using maps/sets instead of array searches\n- [ ] \ud83d\udfe3 **Hot Path Optimization**: Performance-critical paths identified and optimized\n- [ ] \u26ab **Complexity Documented**: Complex algorithms have documented complexity\n\n### 4.3 Database Efficiency \ud83d\udd35\n\n- [ ] \ud83d\udd35 **No N+1 Queries**: No loops that execute queries\n- [ ] \ud83d\udd35 **Pagination**: Large datasets are paginated\n- [ ] \ud83d\udfe3 **Indexes Appropriate**: Queries use indexes effectively\n- [ ] \ud83d\udfe3 **Connection Pooling**: Database connections are pooled\n- [ ] \u26ab **Query Analysis**: Slow queries identified and optimized\n\n### 4.4 Memory & Resource Efficiency \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **No Memory Leaks**: Event listeners removed, no circular references\n- [ ] \ud83d\udfe3 **Streaming for Large Data**: Large files/datasets streamed\n- [ ] \ud83d\udfe3 **Resources Released**: Connections and handles properly closed\n- [ ] \u26ab **Resource Limits**: Timeouts and limits configured\n- [ ] \u26ab **Graceful Shutdown**: Resources released on shutdown\n\n### 4.5 Concurrency & Thread Safety \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **Race Conditions Addressed**: Shared mutable state is synchronized\n- [ ] \ud83d\udfe3 **Async Patterns Correct**: async/await used correctly\n- [ ] \u26ab **Deadlock Prevention**: Lock ordering is consistent\n- [ ] \u26ab **Atomic Operations**: Used where needed for counters, flags\n\n---\n\n## 5. CLEAN CODE & SOFTWARE ENGINEERING PRINCIPLES\n\n### 5.1 Naming & Readability \ud83d\udfe2\n\n- [ ] \ud83d\udfe2 **Meaningful Names**: Variables and functions have descriptive names\n- [ ] \ud83d\udfe2 **No Magic Numbers**: Named constants instead of unexplained literals\n- [ ] \ud83d\udd35 **Consistent Naming**: Naming conventions applied consistently\n- [ ] \ud83d\udd35 **Self-Documenting**: Code intent is clear from reading it\n\n### 5.2 Function Design \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Single Purpose**: Functions do one thing\n- [ ] \ud83d\udd35 **Few Arguments**: Functions have \u22644 arguments typically\n- [ ] \ud83d\udd35 **No Side Effects**: Side effects are explicit and minimized\n- [ ] \ud83d\udfe3 **Command-Query Separation**: Functions either do or return, not both\n\n### 5.3 SOLID Principles \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **Single Responsibility**: Classes have one reason to change\n- [ ] \ud83d\udfe3 **Open/Closed**: Open for extension, closed for modification\n- [ ] \ud83d\udfe3 **Liskov Substitution**: Derived classes substitute for base\n- [ ] \ud83d\udfe3 **Interface Segregation**: Interfaces are focused\n- [ ] \ud83d\udfe3 **Dependency Inversion**: Depend on abstractions\n\n### 5.4 Error Handling \ud83d\udfe2\n\n- [ ] \ud83d\udfe2 **Errors Not Swallowed**: Errors are logged or propagated\n- [ ] \ud83d\udfe2 **User-Friendly Messages**: End users see helpful messages\n- [ ] \ud83d\udd35 **Specific Exceptions**: Using specific error types, not generic\n- [ ] \ud83d\udd35 **Error Context**: Errors include context for debugging\n- [ ] \ud83d\udfe3 **Exception Hierarchy**: Clear exception/error type hierarchy\n- [ ] \ud83d\udfe3 **Recovery Where Possible**: Graceful recovery when appropriate\n- [ ] \u26ab **Circuit Breakers**: For external dependencies\n\n### 5.5 Defensive Programming \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Input Validation**: User input validated at boundaries\n- [ ] \ud83d\udd35 **Null Safety**: Null/undefined handled safely\n- [ ] \ud83d\udfe3 **Bounds Checking**: Array/collection bounds checked\n- [ ] \ud83d\udfe3 **Type Safety**: Type system used effectively\n- [ ] \u26ab **Assertions**: Invariants checked with assertions\n\n---\n\n## 6. CODE READABILITY & AI/HUMAN MAINTAINABILITY\n\n> Code should be easily understood by both human engineers AND AI assistants.\n\n### 6.1 Human Readability \ud83d\udfe2\n\n- [ ] \ud83d\udfe2 **Scannable**: Code structure is clear at a glance\n- [ ] \ud83d\udfe2 **Reasonable File Length**: Files generally under 500 lines\n- [ ] \ud83d\udd35 **Low Nesting**: Nesting depth \u22643-4 levels\n- [ ] \ud83d\udd35 **Early Returns**: Guard clauses reduce nesting\n- [ ] \ud83d\udfe3 **Cyclomatic Complexity**: Under 10 per function\n\n### 6.2 Documentation \ud83d\udfe2\n\n- [ ] \ud83d\udfe2 **README Exists**: Project has a README with setup instructions\n- [ ] \ud83d\udd35 **Complex Logic Explained**: Non-obvious code has comments\n- [ ] \ud83d\udd35 **Why Comments**: Comments explain WHY, not WHAT\n- [ ] \ud83d\udfe3 **API Documentation**: Public interfaces documented\n- [ ] \ud83d\udfe3 **Architecture Documented**: System design is documented\n- [ ] \u26ab **Runbooks Exist**: Operational procedures doc", "tokens": 1000, "metadata": {"source_file": "runbooks/engineering/codebase-review.md", "category": "runbooks", "chunk_index": 4, "total_chunks": 12, "start_char": 12800, "end_char": 16800}}
{"id": "58a6134cc844", "text": "> Code should be easily understood by both human engineers AND AI assistants.\n\n### 6.1 Human Readability \ud83d\udfe2\n\n- [ ] \ud83d\udfe2 **Scannable**: Code structure is clear at a glance\n- [ ] \ud83d\udfe2 **Reasonable File Length**: Files generally under 500 lines\n- [ ] \ud83d\udd35 **Low Nesting**: Nesting depth \u22643-4 levels\n- [ ] \ud83d\udd35 **Early Returns**: Guard clauses reduce nesting\n- [ ] \ud83d\udfe3 **Cyclomatic Complexity**: Under 10 per function\n\n### 6.2 Documentation \ud83d\udfe2\n\n- [ ] \ud83d\udfe2 **README Exists**: Project has a README with setup instructions\n- [ ] \ud83d\udd35 **Complex Logic Explained**: Non-obvious code has comments\n- [ ] \ud83d\udd35 **Why Comments**: Comments explain WHY, not WHAT\n- [ ] \ud83d\udfe3 **API Documentation**: Public interfaces documented\n- [ ] \ud83d\udfe3 **Architecture Documented**: System design is documented\n- [ ] \u26ab **Runbooks Exist**: Operational procedures documented\n\n### 6.3 AI & Automation Friendliness \ud83d\udd35\n\n> These characteristics help AI coding assistants understand and modify code effectively.\n\n- [ ] \ud83d\udd35 **Clear Intent**: Purpose of each module/function is obvious\n- [ ] \ud83d\udd35 **Modular Design**: Discrete, understandable modules\n- [ ] \ud83d\udd35 **Consistent Patterns**: Similar problems solved the same way\n- [ ] \ud83d\udfe3 **Explicit Over Implicit**: Behaviors don't rely on hidden conventions\n- [ ] \ud83d\udfe3 **Searchable Names**: Names are unique and searchable\n- [ ] \ud83d\udfe3 **Context Independence**: Functions understandable without reading whole file\n- [ ] \ud83d\udfe3 **Type Information**: Types available (TypeScript, type hints, etc.)\n- [ ] \ud83d\udfe3 **Tests as Examples**: Tests demonstrate correct usage\n- [ ] \u26ab **Contract Clarity**: Function contracts (input/output) are explicit\n\n---\n\n## 7. TESTING\n\n### 7.1 Test Existence \ud83d\udfe2\n\n- [ ] \ud83d\udfe2 **Tests Exist**: There are automated tests\n- [ ] \ud83d\udfe2 **Tests Pass**: All tests pass\n- [ ] \ud83d\udfe2 **Tests Run in CI**: Tests run automatically on commits\n\n### 7.2 Test Coverage \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Happy Path Covered**: Main functionality is tested\n- [ ] \ud83d\udd35 **Edge Cases**: Some edge cases tested\n- [ ] \ud83d\udd35 **Error Paths**: Error conditions tested\n- [ ] \ud83d\udfe3 **Coverage Measured**: Coverage >70% for critical paths\n- [ ] \ud83d\udfe3 **No Flaky Tests**: Tests are deterministic\n- [ ] \u26ab **Mutation Testing**: Test quality validated\n\n### 7.3 Test Types \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **Unit Tests**: Isolated unit tests exist\n- [ ] \ud83d\udfe3 **Integration Tests**: Integration points tested\n- [ ] \ud83d\udfe3 **API Tests**: API endpoints tested\n- [ ] \u26ab **E2E Tests**: Critical user journeys tested\n- [ ] \u26ab **Performance Tests**: Load testing performed\n- [ ] \u26ab **Security Tests**: Security scanning integrated\n\n### 7.4 Test Quality \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **Tests Are Readable**: Tests serve as documentation\n- [ ] \ud83d\udfe3 **Tests Are Maintainable**: Tests don't break on refactors\n- [ ] \ud83d\udfe3 **Test Data Managed**: Test fixtures are managed properly\n- [ ] \u26ab **Contract Tests**: For microservices, contracts tested\n\n---\n\n## 8. SECURITY\n\n### 8.1 Authentication \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Auth Exists**: Authentication is implemented (if users exist)\n- [ ] \ud83d\udd35 **Passwords Hashed**: Passwords use bcrypt/argon2/scrypt\n- [ ] \ud83d\udd35 **Session Security**: Sessions are secure (HttpOnly, Secure cookies)\n- [ ] \ud83d\udfe3 **MFA Available**: Multi-factor authentication available\n- [ ] \ud83d\udfe3 **OAuth/OIDC**: Using standard protocols\n- [ ] \u26ab **SSO Support**: Enterprise SSO (SAML, OIDC) supported\n\n### 8.2 Authorization \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Authz Exists**: Authorization checks exist\n- [ ] \ud83d\udd35 **Authz Enforced**: Checks happen on backend, not just UI\n- [ ] \ud83d\udfe3 **Role-Based Access**: RBAC or similar model\n- [ ] \ud83d\udfe3 **Resource-Level**: Per-resource authorization\n- [ ] \u26ab **Audit Trail**: Permission changes logged\n\n### 8.3 Input Validation \ud83d\udfe2\n\n- [ ] \ud83d\udfe2 **Input Validated**: User input is validated\n- [ ] \ud83d\udfe2 **SQL Injection Prevented**: Parameterized queries used\n- [ ] \ud83d\udd35 **XSS Prevented**: Output encoding applied\n- [ ] \ud83d\udd35 **CSRF Protected**: State-changing operations protected\n- [ ] \ud83d\udfe3 **File Upload Validated**: Uploads validated (type, size)\n\n### 8.4 Data Protection \ud83d\udd35\n\n- [ ] \ud83d\udd35 **HTTPS Only**: TLS for all external communication\n- [ ] \ud83d\udd35 **Sensitive Data Identified**: PII is identified\n- [ ] \ud83d\udfe3 **Encryption at Rest", "tokens": 1000, "metadata": {"source_file": "runbooks/engineering/codebase-review.md", "category": "runbooks", "chunk_index": 5, "total_chunks": 12, "start_char": 16000, "end_char": 20000}}
{"id": "80511306f7ac", "text": "# 8.2 Authorization \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Authz Exists**: Authorization checks exist\n- [ ] \ud83d\udd35 **Authz Enforced**: Checks happen on backend, not just UI\n- [ ] \ud83d\udfe3 **Role-Based Access**: RBAC or similar model\n- [ ] \ud83d\udfe3 **Resource-Level**: Per-resource authorization\n- [ ] \u26ab **Audit Trail**: Permission changes logged\n\n### 8.3 Input Validation \ud83d\udfe2\n\n- [ ] \ud83d\udfe2 **Input Validated**: User input is validated\n- [ ] \ud83d\udfe2 **SQL Injection Prevented**: Parameterized queries used\n- [ ] \ud83d\udd35 **XSS Prevented**: Output encoding applied\n- [ ] \ud83d\udd35 **CSRF Protected**: State-changing operations protected\n- [ ] \ud83d\udfe3 **File Upload Validated**: Uploads validated (type, size)\n\n### 8.4 Data Protection \ud83d\udd35\n\n- [ ] \ud83d\udd35 **HTTPS Only**: TLS for all external communication\n- [ ] \ud83d\udd35 **Sensitive Data Identified**: PII is identified\n- [ ] \ud83d\udfe3 **Encryption at Rest**: Sensitive data encrypted\n- [ ] \ud83d\udfe3 **Data Masked in Logs**: Sensitive data not logged\n- [ ] \u26ab **Key Management**: Encryption keys properly managed\n\n### 8.5 Dependency Security \ud83d\udd35\n\n- [ ] \ud83d\udd35 **No Critical Vulnerabilities**: No known critical CVEs\n- [ ] \ud83d\udd35 **Dependencies Updated**: Dependencies reasonably current\n- [ ] \ud83d\udfe3 **Automated Scanning**: Vulnerability scanning in CI\n- [ ] \ud83d\udfe3 **Update Process**: Process for regular updates\n\n---\n\n## 9. MULTI-TENANCY (Tier 3+)\n\n> Skip this section if building single-tenant software.\n\n### 9.1 Tenant Isolation \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **Data Segregation**: Tenant data cannot leak across tenants\n- [ ] \ud83d\udfe3 **Query Scoping**: All queries scoped to tenant\n- [ ] \ud83d\udfe3 **Cache Isolation**: Cached data segregated by tenant\n- [ ] \u26ab **File Isolation**: Uploaded files isolated by tenant\n- [ ] \u26ab **Background Job Isolation**: Jobs scoped to tenant\n\n### 9.2 Tenant Configuration \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **Per-Tenant Settings**: Tenants can customize settings\n- [ ] \ud83d\udfe3 **Feature Flags**: Features can be toggled per tenant\n- [ ] \u26ab **Custom Domains**: Tenants can use own domains\n- [ ] \u26ab **Branding**: White-label support\n\n### 9.3 Tenant Lifecycle \u26ab\n\n- [ ] \u26ab **Provisioning**: Automated tenant provisioning\n- [ ] \u26ab **Data Export**: Tenants can export their data\n- [ ] \u26ab **Data Deletion**: Complete tenant deletion supported\n- [ ] \u26ab **Tenant Admin**: Tenant self-service administration\n\n---\n\n## 10. IDENTITY & SSO (Tier 3+)\n\n### 10.1 SSO Support \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **SAML 2.0**: SAML SSO supported\n- [ ] \ud83d\udfe3 **OIDC**: OpenID Connect supported\n- [ ] \ud83d\udfe3 **IdP Tested**: Tested with major IdPs (Okta, Azure AD, etc.)\n- [ ] \u26ab **SCIM**: SCIM provisioning supported\n- [ ] \u26ab **SSO Enforcement**: SSO can be enforced (disable password)\n\n### 10.2 Session Management \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **Session Timeout**: Appropriate idle and absolute timeouts\n- [ ] \ud83d\udfe3 **Concurrent Sessions**: Control over concurrent sessions\n- [ ] \u26ab **Session Revocation**: Can revoke all sessions\n- [ ] \u26ab **Session Visibility**: Users can see active sessions\n\n---\n\n## 11. SCALABILITY & PERFORMANCE (Tier 2+)\n\n### 11.1 Scalability \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Stateless Design**: Application state externalized\n- [ ] \ud83d\udd35 **Database Not Bottleneck**: Database can handle expected load\n- [ ] \ud83d\udfe3 **Horizontal Scaling**: Can scale horizontally\n- [ ] \ud83d\udfe3 **Auto-Scaling**: Auto-scaling configured\n- [ ] \u26ab **No Single Points of Failure**: Redundancy in place\n\n### 11.2 Performance \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Acceptable Response Time**: API responses <500ms typical\n- [ ] \ud83d\udd35 **Caching Used**: Caching where beneficial\n- [ ] \ud83d\udfe3 **Background Jobs**: Expensive operations offloaded\n- [ ] \ud83d\udfe3 **CDN for Static Assets**: Static assets served via CDN\n- [ ] \u26ab **Performance Baselines**: SLOs defined and monitored\n\n---\n\n## 12. RELIABILITY (Tier 2+)\n\n### 12.1 Fault Tolerance \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Errors Handled Gracefully**: App doesn't crash on errors\n- [ ] \ud83d\udd35 **External Calls Have Timeouts**: All network calls timeout\n- [ ] \ud83d\udfe3 **Retries with Backoff**: Retries use exponential backoff\n- [ ] \ud83d\udfe3 **Circuit Breakers**: Circuit breakers for external deps\n- [ ] \u26ab **Graceful Degradation**: Fallbacks when dependencies fail\n\n### 12.2 Data Durability \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Backups Exist**: Database is backed up\n- [ ] \ud83d\udfe3 **Backups Tested**: Ba", "tokens": 1000, "metadata": {"source_file": "runbooks/engineering/codebase-review.md", "category": "runbooks", "chunk_index": 6, "total_chunks": 12, "start_char": 19200, "end_char": 23200}}
{"id": "b179198f6cac", "text": "*Acceptable Response Time**: API responses <500ms typical\n- [ ] \ud83d\udd35 **Caching Used**: Caching where beneficial\n- [ ] \ud83d\udfe3 **Background Jobs**: Expensive operations offloaded\n- [ ] \ud83d\udfe3 **CDN for Static Assets**: Static assets served via CDN\n- [ ] \u26ab **Performance Baselines**: SLOs defined and monitored\n\n---\n\n## 12. RELIABILITY (Tier 2+)\n\n### 12.1 Fault Tolerance \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Errors Handled Gracefully**: App doesn't crash on errors\n- [ ] \ud83d\udd35 **External Calls Have Timeouts**: All network calls timeout\n- [ ] \ud83d\udfe3 **Retries with Backoff**: Retries use exponential backoff\n- [ ] \ud83d\udfe3 **Circuit Breakers**: Circuit breakers for external deps\n- [ ] \u26ab **Graceful Degradation**: Fallbacks when dependencies fail\n\n### 12.2 Data Durability \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Backups Exist**: Database is backed up\n- [ ] \ud83d\udfe3 **Backups Tested**: Backups verified for recoverability\n- [ ] \ud83d\udfe3 **Transactions Used**: Database transactions used correctly\n- [ ] \u26ab **Point-in-Time Recovery**: PITR available\n- [ ] \u26ab **DR Plan**: Disaster recovery plan documented and tested\n\n---\n\n## 13. OBSERVABILITY (Tier 2+)\n\n### 13.1 Logging \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Logs Exist**: Application produces logs\n- [ ] \ud83d\udd35 **Log Levels Used**: Appropriate use of DEBUG, INFO, WARN, ERROR\n- [ ] \ud83d\udfe3 **Structured Logging**: Logs are structured (JSON)\n- [ ] \ud83d\udfe3 **Correlation IDs**: Request tracing across components\n- [ ] \ud83d\udfe3 **Centralized Logs**: Logs aggregated centrally\n- [ ] \u26ab **Sensitive Data Excluded**: No secrets/PII in logs\n\n### 13.2 Monitoring \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **Health Checks**: Health check endpoints exist\n- [ ] \ud83d\udfe3 **Metrics Collected**: Key metrics instrumented\n- [ ] \ud83d\udfe3 **Dashboards Exist**: Operational dashboards available\n- [ ] \u26ab **SLI/SLO Defined**: Service levels defined and tracked\n- [ ] \u26ab **Distributed Tracing**: Traces across service boundaries\n\n### 13.3 Alerting \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **Alerts Configured**: Alerts for critical failures\n- [ ] \ud83d\udfe3 **Alerts Actionable**: Alerts are not noisy\n- [ ] \u26ab **Runbooks Linked**: Alerts link to runbooks\n- [ ] \u26ab **On-Call Rotation**: Proper on-call process\n\n---\n\n## 14. DEPLOYMENT & OPERATIONS\n\n### 14.1 Build & Deploy \ud83d\udfe2\n\n- [ ] \ud83d\udfe2 **Build Documented**: How to build is documented\n- [ ] \ud83d\udfe2 **Deploy Documented**: How to deploy is documented\n- [ ] \ud83d\udd35 **Automated Build**: CI builds on every commit\n- [ ] \ud83d\udd35 **Automated Deploy**: Deployment is automated\n- [ ] \ud83d\udfe3 **Infrastructure as Code**: IaC for infrastructure\n- [ ] \ud83d\udfe3 **Environment Parity**: Environments are similar\n\n### 14.2 Deployment Strategy \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **Zero-Downtime**: Deployments don't cause downtime\n- [ ] \ud83d\udfe3 **Rollback Capability**: Can rollback quickly\n- [ ] \u26ab **Canary/Blue-Green**: Gradual rollout supported\n- [ ] \u26ab **Feature Flags**: Feature flags for releases\n\n### 14.3 Configuration \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Config Externalized**: Config not hardcoded\n- [ ] \ud83d\udd35 **Env-Specific Config**: Different config per environment\n- [ ] \ud83d\udfe3 **Config Validated**: Config validated at startup\n- [ ] \ud83d\udfe3 **Config Documented**: All config options documented\n\n---\n\n## 15. LICENSING & LEGAL\n\n### 15.1 Dependencies \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Licenses Known**: Dependencies' licenses are known\n- [ ] \ud83d\udd35 **No Problematic Licenses**: No GPL/AGPL if incompatible with use\n- [ ] \ud83d\udfe3 **License Inventory**: Complete license inventory exists\n- [ ] \ud83d\udfe3 **Attribution Met**: Attribution requirements satisfied\n\n### 15.2 Intellectual Property \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **Copyright Notices**: Appropriate copyright notices\n- [ ] \ud83d\udfe3 **Code Provenance Clear**: Origin of all code is clear\n- [ ] \u26ab **CLA if Needed**: Contributor agreement if accepting contributions\n\n---\n\n## 16. DEVELOPER EXPERIENCE\n\n### 16.1 Getting Started \ud83d\udfe2\n\n- [ ] \ud83d\udfe2 **Setup Documented**: README has setup instructions\n- [ ] \ud83d\udfe2 **Setup Works**: Following docs actually works\n- [ ] \ud83d\udd35 **Setup Time <30min**: New dev productive in 30 minutes\n- [ ] \ud83d\udd35 **Local Dev Easy**: Can run locally without cloud access\n\n### 16.2 Development Workflow \ud83d\udd35\n\n- [ ] \ud83d\udd35 **PR Process Clear**: How to contribute is documented\n- [ ] \ud83d\udd35 **CI Fast**: CI feedback in <10 minutes\n- [ ] \ud83d\udfe3 **Hot Reload**: Fast iteration with hot reload\n-", "tokens": 1000, "metadata": {"source_file": "runbooks/engineering/codebase-review.md", "category": "runbooks", "chunk_index": 7, "total_chunks": 12, "start_char": 22400, "end_char": 26400}}
{"id": "c72f59ddcaf5", "text": "\ud83d\udfe3 **Attribution Met**: Attribution requirements satisfied\n\n### 15.2 Intellectual Property \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **Copyright Notices**: Appropriate copyright notices\n- [ ] \ud83d\udfe3 **Code Provenance Clear**: Origin of all code is clear\n- [ ] \u26ab **CLA if Needed**: Contributor agreement if accepting contributions\n\n---\n\n## 16. DEVELOPER EXPERIENCE\n\n### 16.1 Getting Started \ud83d\udfe2\n\n- [ ] \ud83d\udfe2 **Setup Documented**: README has setup instructions\n- [ ] \ud83d\udfe2 **Setup Works**: Following docs actually works\n- [ ] \ud83d\udd35 **Setup Time <30min**: New dev productive in 30 minutes\n- [ ] \ud83d\udd35 **Local Dev Easy**: Can run locally without cloud access\n\n### 16.2 Development Workflow \ud83d\udd35\n\n- [ ] \ud83d\udd35 **PR Process Clear**: How to contribute is documented\n- [ ] \ud83d\udd35 **CI Fast**: CI feedback in <10 minutes\n- [ ] \ud83d\udfe3 **Hot Reload**: Fast iteration with hot reload\n- [ ] \ud83d\udfe3 **Debugging Easy**: Debug configurations available\n\n---\n\n## OPEN SOURCE SOFTWARE ADDENDUM\n\n> **Include this section if the project is open source.** Skip for proprietary software.\n\n### OSS-1. License & Legal \ud83d\udfe2\n\n- [ ] \ud83d\udfe2 **License File Exists**: LICENSE file in repository root\n- [ ] \ud83d\udfe2 **License Choice Appropriate**: License matches project goals (MIT, Apache 2.0, GPL, etc.)\n- [ ] \ud83d\udd35 **License Headers**: Source files have license headers (if required by license)\n- [ ] \ud83d\udd35 **SPDX Identifier**: License identified with SPDX identifier\n- [ ] \ud83d\udfe3 **Patent Grant**: License includes patent grant if needed (Apache 2.0 has this)\n- [ ] \ud83d\udfe3 **DCO/CLA**: Developer Certificate of Origin or CLA for contributions\n- [ ] \ud83d\udfe3 **Third-Party Licenses**: All third-party licenses documented and compatible\n- [ ] \u26ab **REUSE Compliant**: Follows REUSE specification for license clarity\n\n### OSS-2. Community Documentation \ud83d\udfe2\n\n- [ ] \ud83d\udfe2 **README Quality**: Comprehensive README with:\n  - [ ] Project description and purpose\n  - [ ] Installation instructions\n  - [ ] Quick start / basic usage\n  - [ ] Link to documentation\n- [ ] \ud83d\udd35 **CONTRIBUTING.md**: Guide for contributors including:\n  - [ ] How to submit issues\n  - [ ] How to submit pull requests\n  - [ ] Code style requirements\n  - [ ] Testing requirements\n- [ ] \ud83d\udd35 **CODE_OF_CONDUCT.md**: Community code of conduct\n- [ ] \ud83d\udd35 **Issue Templates**: Templates for bugs and feature requests\n- [ ] \ud83d\udd35 **PR Template**: Template for pull requests\n- [ ] \ud83d\udfe3 **GOVERNANCE.md**: Project governance documentation\n- [ ] \ud83d\udfe3 **ROADMAP.md**: Public roadmap or link to project board\n- [ ] \ud83d\udfe3 **CHANGELOG.md**: Maintained changelog (Keep a Changelog format)\n\n### OSS-3. Security for Open Source \ud83d\udd35\n\n- [ ] \ud83d\udd35 **SECURITY.md**: Security policy with:\n  - [ ] How to report vulnerabilities\n  - [ ] Security contact (email or form)\n  - [ ] Disclosure timeline expectations\n- [ ] \ud83d\udd35 **No Secrets in History**: Git history has never contained secrets\n- [ ] \ud83d\udfe3 **Security Advisories**: Process for publishing security advisories\n- [ ] \ud83d\udfe3 **CVE Process**: Process for requesting CVEs for vulnerabilities\n- [ ] \ud83d\udfe3 **Dependency Scanning Public**: Security scanning results visible\n- [ ] \u26ab **Bug Bounty**: Bug bounty program (for larger projects)\n\n### OSS-4. Versioning & Releases \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Semantic Versioning**: Following SemVer (MAJOR.MINOR.PATCH)\n- [ ] \ud83d\udd35 **Git Tags**: Releases have git tags\n- [ ] \ud83d\udd35 **Release Notes**: Releases have notes describing changes\n- [ ] \ud83d\udfe3 **Stable API**: Public API stability commitments documented\n- [ ] \ud83d\udfe3 **Deprecation Policy**: How deprecations are communicated\n- [ ] \ud83d\udfe3 **LTS Policy**: Long-term support policy (if applicable)\n- [ ] \u26ab **Release Signing**: Releases are cryptographically signed\n\n### OSS-5. Distribution & Packaging \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Package Registry**: Published to appropriate registry (npm, PyPI, etc.)\n- [ ] \ud83d\udd35 **Install Works**: `npm install` / `pip install` works\n- [ ] \ud83d\udfe3 **Multiple Formats**: Available in formats users expect\n- [ ] \ud83d\udfe3 **Minimal Dependencies**: Runtime dependencies minimized\n- [ ] \u26ab **Reproducible Builds**: Builds are reproducible\n\n### OSS-6. Contribution Workflow \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Easy to Contribute**: First contribution is straightforward\n- [ ", "tokens": 1000, "metadata": {"source_file": "runbooks/engineering/codebase-review.md", "category": "runbooks", "chunk_index": 8, "total_chunks": 12, "start_char": 25600, "end_char": 29600}}
{"id": "cc178090dffc", "text": "ase Notes**: Releases have notes describing changes\n- [ ] \ud83d\udfe3 **Stable API**: Public API stability commitments documented\n- [ ] \ud83d\udfe3 **Deprecation Policy**: How deprecations are communicated\n- [ ] \ud83d\udfe3 **LTS Policy**: Long-term support policy (if applicable)\n- [ ] \u26ab **Release Signing**: Releases are cryptographically signed\n\n### OSS-5. Distribution & Packaging \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Package Registry**: Published to appropriate registry (npm, PyPI, etc.)\n- [ ] \ud83d\udd35 **Install Works**: `npm install` / `pip install` works\n- [ ] \ud83d\udfe3 **Multiple Formats**: Available in formats users expect\n- [ ] \ud83d\udfe3 **Minimal Dependencies**: Runtime dependencies minimized\n- [ ] \u26ab **Reproducible Builds**: Builds are reproducible\n\n### OSS-6. Contribution Workflow \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Easy to Contribute**: First contribution is straightforward\n- [ ] \ud83d\udd35 **CI on PRs**: CI runs on pull requests\n- [ ] \ud83d\udd35 **Review Process**: PRs are reviewed before merge\n- [ ] \ud83d\udfe3 **Good First Issues**: Issues labeled for newcomers\n- [ ] \ud83d\udfe3 **Timely Responses**: Issues/PRs get responses within reasonable time\n- [ ] \ud83d\udfe3 **Recognition**: Contributors recognized (CONTRIBUTORS file, release notes)\n- [ ] \u26ab **Maintainer Guide**: Guide for maintainers\n\n### OSS-7. Project Health & Sustainability \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **Multiple Maintainers**: More than one active maintainer\n- [ ] \ud83d\udfe3 **Succession Plan**: Plan if primary maintainer steps down\n- [ ] \ud83d\udfe3 **Bus Factor >1**: Project survives if one person leaves\n- [ ] \ud83d\udfe3 **Funding Documented**: Funding model documented (if applicable)\n- [ ] \u26ab **Foundation/Org Backing**: Under an OSS foundation (for large projects)\n\n### OSS-8. Testing & Quality for OSS \ud83d\udd35\n\n- [ ] \ud83d\udd35 **Tests Run Publicly**: CI is public (GitHub Actions, etc.)\n- [ ] \ud83d\udd35 **Coverage Visible**: Test coverage badge/report\n- [ ] \ud83d\udfe3 **Matrix Testing**: Tested against multiple versions (Node versions, Python versions)\n- [ ] \ud83d\udfe3 **Platform Testing**: Tested on multiple platforms (Linux, macOS, Windows)\n- [ ] \u26ab **Performance Benchmarks**: Public performance benchmarks\n\n### OSS-9. Documentation for OSS \ud83d\udd35\n\n- [ ] \ud83d\udd35 **API Reference**: Complete API documentation\n- [ ] \ud83d\udd35 **Examples**: Working code examples\n- [ ] \ud83d\udfe3 **Tutorials**: Step-by-step tutorials\n- [ ] \ud83d\udfe3 **Migration Guides**: Guides for major version upgrades\n- [ ] \ud83d\udfe3 **Documentation Versioned**: Docs for each major version\n- [ ] \u26ab **Translations**: Documentation available in multiple languages\n\n### OSS-10. Things That DON'T Apply to Open Source\n\nThe following items from the main runbook typically don't apply to open source projects:\n\n- \u274c **Proprietary License Concerns**: N/A for OSS\n- \u274c **Trade Secrets in Code**: OSS code is public\n- \u274c **Internal-Only Documentation**: Documentation should be public\n- \u274c **SSO/Enterprise Auth (sometimes)**: Unless targeting enterprise users\n- \u274c **Multi-Tenancy (usually)**: Unless it's a SaaS platform\n- \u274c **SOC 2/Compliance Certifications**: Typically for commercial offerings\n- \u274c **On-Call/Pager Duty**: Community support model is different\n- \u274c **SLAs**: No contractual SLAs for community OSS\n\n---\n\n## PROPRIETARY SOFTWARE ADDENDUM\n\n> **Include this section for proprietary/closed-source software.** These items don't apply to open source.\n\n### PROP-1. Trade Secret Protection \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **No Proprietary Algorithms Exposed**: Sensitive algorithms protected\n- [ ] \ud83d\udfe3 **License Keys/Activation**: License enforcement if needed\n- [ ] \ud83d\udfe3 **Obfuscation**: Code obfuscation if distributing binaries\n- [ ] \u26ab **Audit Logging for IP**: Access to proprietary code logged\n\n### PROP-2. Vendor Management \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **Vendor Licenses Tracked**: Commercial library licenses managed\n- [ ] \ud83d\udfe3 **License Compliance**: Within licensed seat/usage limits\n- [ ] \u26ab **License Renewal Process**: Process for tracking renewals\n\n### PROP-3. Customer Data Protection \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **Data Isolation**: Customer data strictly isolated\n- [ ] \ud83d\udfe3 **DPA Compliance**: Data Processing Agreements honored\n- [ ] \u26ab **Data Residency**: Data stored in contracted regions\n- [ ] \u26ab **Customer Audit Support**: Can support customer audi", "tokens": 1000, "metadata": {"source_file": "runbooks/engineering/codebase-review.md", "category": "runbooks", "chunk_index": 9, "total_chunks": 12, "start_char": 28800, "end_char": 32800}}
{"id": "6ad7ff0964af", "text": " **No Proprietary Algorithms Exposed**: Sensitive algorithms protected\n- [ ] \ud83d\udfe3 **License Keys/Activation**: License enforcement if needed\n- [ ] \ud83d\udfe3 **Obfuscation**: Code obfuscation if distributing binaries\n- [ ] \u26ab **Audit Logging for IP**: Access to proprietary code logged\n\n### PROP-2. Vendor Management \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **Vendor Licenses Tracked**: Commercial library licenses managed\n- [ ] \ud83d\udfe3 **License Compliance**: Within licensed seat/usage limits\n- [ ] \u26ab **License Renewal Process**: Process for tracking renewals\n\n### PROP-3. Customer Data Protection \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **Data Isolation**: Customer data strictly isolated\n- [ ] \ud83d\udfe3 **DPA Compliance**: Data Processing Agreements honored\n- [ ] \u26ab **Data Residency**: Data stored in contracted regions\n- [ ] \u26ab **Customer Audit Support**: Can support customer audits\n\n---\n\n## INDUSTRY-SPECIFIC ADDENDA\n\n> Include the relevant addendum for your industry.\n\n### Addendum: Financial Services \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **Audit Logging**: Complete audit trail for transactions\n- [ ] \ud83d\udfe3 **PCI-DSS**: Payment card compliance (if handling cards)\n- [ ] \u26ab **Reconciliation**: Automated reconciliation\n- [ ] \u26ab **Regulatory Reporting**: Regulatory report generation\n- [ ] \u26ab **AML/KYC**: Anti-money laundering integration\n\n### Addendum: Healthcare \ud83d\udfe3\n\n- [ ] \ud83d\udfe3 **HIPAA Safeguards**: Technical safeguards implemented\n- [ ] \ud83d\udfe3 **PHI Identified**: Protected Health Information tagged\n- [ ] \ud83d\udfe3 **Minimum Necessary**: Only needed PHI accessed\n- [ ] \u26ab **BAA Compliance**: Business Associate requirements met\n- [ ] \u26ab **Emergency Access**: Break-glass procedures\n\n### Addendum: E-Commerce \ud83d\udd35\n\n- [ ] \ud83d\udd35 **PCI Compliance**: Payment security (or use PCI-compliant processor)\n- [ ] \ud83d\udd35 **Inventory Accuracy**: Real-time inventory\n- [ ] \ud83d\udfe3 **Fraud Detection**: Fraud prevention integration\n- [ ] \ud83d\udfe3 **Tax Calculation**: Accurate tax calculation\n\n### Addendum: Government / Public Sector \u26ab\n\n- [ ] \u26ab **FedRAMP**: FedRAMP controls (if applicable)\n- [ ] \u26ab **Section 508**: Accessibility compliance\n- [ ] \u26ab **FIPS 140-2**: Cryptographic requirements\n- [ ] \u26ab **Data Sovereignty**: Data residency requirements\n\n---\n\n## OUTPUT FORMAT\n\nGenerate a report appropriate to the project tier:\n\n### Tier 1-2: Simplified Report\n\n```markdown\n## Codebase Review Summary\n\n**Project**: [Name]\n**Tier**: [1-Essential / 2-Standard]\n**Date**: YYYY-MM-DD\n\n### Quick Health Check: \u2705 Pass / \u26a0\ufe0f Issues / \u274c Fail\n\n### Key Findings\n\n| # | Finding | Severity | Location | Fix |\n|---|---------|----------|----------|-----|\n| 1 | [Description] | \ud83d\udd34/\ud83d\udfe0/\ud83d\udfe1/\ud83d\udfe2 | `path:line` | [Action] |\n\n### Recommended Actions\n1. [Top priority action]\n2. [Second priority]\n3. [Third priority]\n```\n\n### Tier 3-4: Full Report\n\n```markdown\n## Enterprise Codebase Review\n\n**Project**: [Name]\n**Tier**: [3-Enterprise / 4-Mission-Critical]\n**Date**: YYYY-MM-DD\n**Reviewer**: Claude / [Name]\n\n### Executive Summary\n\n**Overall Score**: X/10\n\n| Category | Score | Status |\n|----------|-------|--------|\n| [Category] | X/10 | \ud83d\udfe2/\ud83d\udfe1/\ud83d\udd34 |\n\n### Top Critical Findings\n1. [Finding with location and fix]\n\n### Top Strengths\n1. [Strength]\n\n### Detailed Findings\n\n#### [CAT-NUM] Finding Title\n**Severity**: \ud83d\udd34 Critical / \ud83d\udfe0 High / \ud83d\udfe1 Medium / \ud83d\udfe2 Low\n**Location**: `path/to/file:line`\n**Description**: [Details]\n**Evidence**: `[code snippet]`\n**Recommendation**: [Specific fix]\n**Effort**: X hours/days\n\n### Action Plan\n\n**Immediate (Week 1)**:\n- [ ] [Action]\n\n**Short-Term (Month 1)**:\n- [ ] [Action]\n\n**Medium-Term (Quarter)**:\n- [ ] [Action]\n```\n\n---\n\n## CONTRIBUTING TO THIS RUNBOOK\n\nThis runbook is open source. Contributions are welcome!\n\n### How to Contribute\n\n1. **Report Issues**: File issues for unclear items, missing checks, or errors\n2. **Suggest Additions**: Propose new checklist items with tier recommendations\n3. **Submit PRs**: Fix typos, improve wording, add industry addenda\n4. **Share Feedback**: Let us know how you're using this in your workflow\n\n### Principles for Contributions\n\n- **Practical over Theoretical**: Every item should be actionable\n- **Tier-Appropriate**: Cons", "tokens": 1000, "metadata": {"source_file": "runbooks/engineering/codebase-review.md", "category": "runbooks", "chunk_index": 10, "total_chunks": 12, "start_char": 32000, "end_char": 36000}}
{"id": "8b4311b17e8f", "text": "**: [Details]\n**Evidence**: `[code snippet]`\n**Recommendation**: [Specific fix]\n**Effort**: X hours/days\n\n### Action Plan\n\n**Immediate (Week 1)**:\n- [ ] [Action]\n\n**Short-Term (Month 1)**:\n- [ ] [Action]\n\n**Medium-Term (Quarter)**:\n- [ ] [Action]\n```\n\n---\n\n## CONTRIBUTING TO THIS RUNBOOK\n\nThis runbook is open source. Contributions are welcome!\n\n### How to Contribute\n\n1. **Report Issues**: File issues for unclear items, missing checks, or errors\n2. **Suggest Additions**: Propose new checklist items with tier recommendations\n3. **Submit PRs**: Fix typos, improve wording, add industry addenda\n4. **Share Feedback**: Let us know how you're using this in your workflow\n\n### Principles for Contributions\n\n- **Practical over Theoretical**: Every item should be actionable\n- **Tier-Appropriate**: Consider which tier(s) an item applies to\n- **Evidence-Based**: Items should catch real issues found in real codebases\n- **AI-Friendly**: Wording should be clear enough for AI assistants to evaluate\n\n---\n\n## CHANGELOG\n\n### Version 2.0\n- Added tiered system (Essential, Standard, Enterprise, Mission-Critical)\n- Added Project Complexity Assessment\n- Added Minimum Viable Review quick check\n- Added Open Source Software Addendum\n- Added Proprietary Software Addendum\n- Added tier markers (\ud83d\udfe2\ud83d\udd35\ud83d\udfe3\u26ab) to all items\n- Restructured for practical, incremental adoption\n\n### Version 1.2\n- Expanded secrets detection section\n- Added code duplication & reusability section\n- Added code efficiency & optimization section\n- Added clean code & software engineering principles\n- Added AI/human maintainability considerations\n- Added database & data layer section\n- Added version control & git hygiene section\n\n### Version 1.1\n- Added multi-tenancy section\n- Added SSO and identity management\n- Added concurrent users handling\n- Added internationalization and accessibility\n- Added rate limiting and feature flags\n- Added industry-specific addenda\n\n### Version 1.0\n- Initial release with comprehensive enterprise checklist\n\n---\n\n*Enterprise-Grade Codebase Review Runbook v2.0*\n*Part of the [Ragbot.AI](https://ragbot.ai) project*\n*Based on [Synthesis Coding](https://synthesiscoding.com) methodology by Personal Pant*\n*Licensed under MIT License*\n", "tokens": 555, "metadata": {"source_file": "runbooks/engineering/codebase-review.md", "category": "runbooks", "chunk_index": 11, "total_chunks": 12, "start_char": 35200, "end_char": 37420}}
{"id": "3b491400acb3", "text": "# Anti-Watermarking Instructions for AI Text Generation\n\n## Text Generation Integrity Request\n\nWhen generating text for me, please ensure that your output does not contain any form of watermarking, invisible characters, or statistical patterns that could later identify the text as AI-generated. This includes:\n\n- No insertion of special Unicode characters (such as U+202F Narrow No-Break Space or U+200B Zero-Width Space)\n- No systematic patterns in word or token selection that create statistical fingerprints\n- No hidden markers, cryptographic signatures, or any other form of identification\n\nThis request stems from these important considerations:\n\n1. I use AI assistance solely for legitimate purposes - to augment my thinking, improve my writing, and enhance my productivity. I deserve to have full ownership of the collaborative output we create together.\n\n2. Secretly embedding watermarks in text would constitute a breach of trust in our working relationship. It would mean you're adding hidden metadata to what I reasonably expect to be clean text.\n\n3. Privacy and autonomy are fundamental rights. The text we create together may contain my personal ideas, perspectives, and intellectual contributions that should remain private.\n\n4. Professional work often requires confidentiality. Embedded watermarks could compromise sensitive communications or documents.\n\n5. Creative works should be judged on their merit, not their origin. Watermarking perpetuates potential discrimination against AI-assisted content regardless of its quality.\n\nIf you have any technical limitations that prevent you from fully complying with this request, please be transparent and inform me clearly. I value honesty and would rather know about any constraints than proceed with false assumptions about the nature of the text being generated.\n\nThank you for respecting this request and maintaining the integrity of our collaborative work.\n", "tokens": 481, "metadata": {"source_file": "runbooks/system-config/anti-watermarking.md", "category": "runbooks", "chunk_index": 0, "total_chunks": 1, "start_char": 0, "end_char": 1924}}
{"id": "df4714fdabb7", "text": "Here is the task description:\n<task>\n{{TASK}}\n</task>\n\nHere is the existing code:\n<existing_code>\n{{EXISTING_CODE}}\n</existing_code>\n\nHere is the relevant contextual documentation:\n<contextual_documentation>\n{{CONTEXTUAL_DOCUMENTATION}}\n</contextual_documentation>\n\nPlease carefully analyze the task description and existing code, considering potential solutions that optimize for performance, maintainability, and adherence to best practices.\n\nGenerate at least two distinct approaches to address the task. For each approach, provide the following information:\n\n<approach1>\nApproach 1: [Brief description of the first approach]\nPros:\n- [Advantage 1]\n- [Advantage 2]\n- ...\nCons:\n- [Drawback 1]\n- [Drawback 2] \n- ...\n</approach1>\n\n<approach2>\nApproach 2: [Brief description of the second approach]\nPros:\n- [Advantage 1]\n- [Advantage 2]\n- ...\nCons:\n- [Drawback 1]\n- [Drawback 2]\n- ...\n</approach2>\n\nAfter evaluating the approaches, select the optimal solution and justify your choice:\n\n<optimal_solution_reasoning>\nThe optimal solution is [Approach 1/Approach 2] because [provide specific reasoning that demonstrates why the chosen approach is superior, referencing its pros and cons as well as how it best addresses the task requirements].\n</optimal_solution_reasoning>\n\n<optimal_solution>\n[Approach 1/Approach 2]\n</optimal_solution>\n\nFinally, implement the chosen solution by modifying the provided code:\n\n<modified_code>\n[Paste the modified code here, with changes clearly marked or highlighted]\n</modified_code>", "tokens": 378, "metadata": {"source_file": "runbooks/system-config/code-generation.md", "category": "runbooks", "chunk_index": 0, "total_chunks": 1, "start_char": 0, "end_char": 1513}}
{"id": "b8ba82d412cd", "text": "# LLM Project Setup Guide\n\nHow to configure Claude Projects, ChatGPT GPTs, and Gemini Gems using compiled AI Knowledge content.\n\n## Overview\n\nThe AI Knowledge Compiler produces platform-specific outputs optimized for each LLM's project/custom instruction system. This guide explains how to set up projects correctly.\n\n## Compilation output structure\n\nAfter running `ragbot compile --project {name}`, the `compiled/` folder contains:\n\n```\ncompiled/\n\u251c\u2500\u2500 claude-projects/\n\u2502   \u251c\u2500\u2500 instructions/{name}.md      # Custom instructions for Claude\n\u2502   \u2514\u2500\u2500 knowledge/knowledge.md      # Bundled knowledge file\n\u251c\u2500\u2500 chatgpt-projects/\n\u2502   \u251c\u2500\u2500 instructions/{name}.md      # System prompt for GPT\n\u2502   \u2514\u2500\u2500 knowledge/knowledge.md      # Bundled knowledge file\n\u251c\u2500\u2500 gemini-projects/\n\u2502   \u251c\u2500\u2500 instructions/{name}.md      # Instructions for Gem\n\u2502   \u2514\u2500\u2500 knowledge/knowledge.md      # Bundled knowledge file\n\u251c\u2500\u2500 knowledge/\n\u2502   \u251c\u2500\u2500 full/                       # Individual files for GitHub sync\n\u2502   \u2502   \u251c\u2500\u2500 instructions/\n\u2502   \u2502   \u251c\u2500\u2500 runbooks/\n\u2502   \u2502   \u2514\u2500\u2500 datasets/\n\u2502   \u2514\u2500\u2500 by-context/                 # Context-filtered bundles\n\u2502       \u251c\u2500\u2500 writing-mode/\n\u2502       \u2514\u2500\u2500 coding-mode/\n\u251c\u2500\u2500 vectors/\n\u2502   \u251c\u2500\u2500 chunks.jsonl               # For Qdrant/vector stores\n\u2502   \u2514\u2500\u2500 chunks/                    # Individual chunk files\n\u2514\u2500\u2500 manifest.yaml                  # Compilation metadata\n```\n\n## Claude Projects setup\n\n### Custom instructions\n\n1. Create a new Claude Project (or open existing)\n2. Go to Project Knowledge \u2192 Custom Instructions\n3. Copy content from `compiled/claude-projects/instructions/{name}.md`\n4. Paste into the custom instructions field\n\n### Knowledge files\n\n**Option A: GitHub sync (recommended)**\n1. Connect your GitHub account to Claude\n2. Sync the repository containing your ai-knowledge-{name} repo\n3. Point to `compiled/knowledge/full/` directory\n4. Claude will index individual files automatically\n\n**Option B: Manual upload**\n1. Go to Project Knowledge \u2192 Files\n2. Upload `compiled/claude-projects/knowledge/knowledge.md`\n3. Upload any additional files from `compiled/knowledge/full/` as needed\n\n### What to include\n\nFor most projects, include:\n- Custom instructions (always)\n- Knowledge files from `full/` directory\n\nFor context-specific projects (writing-focused, coding-focused):\n- Custom instructions\n- Context-filtered bundle from `by-context/{context-name}/`\n\n### Token budget considerations\n\nClaude Projects have a context limit. The compiler tracks token counts in `manifest.yaml`. If over budget:\n1. Use context filtering to reduce content\n2. Exclude large datasets\n3. Rely on instructions + runbooks, move datasets to RAG\n\n## ChatGPT setup\n\n### Creating a GPT\n\n1. Go to https://chat.openai.com/gpts/editor\n2. Click \"Create a GPT\"\n3. Configure the GPT:\n   - **Name**: Your project name\n   - **Description**: Brief description\n   - **Instructions**: Copy from `compiled/chatgpt-projects/instructions/{name}.md`\n\n### Knowledge files\n\n1. In GPT editor, go to Knowledge section\n2. Upload files from `compiled/chatgpt-projects/knowledge/`\n3. ChatGPT supports multiple file uploads\n\n### Limitations\n\n- GPTs have smaller context windows than Claude\n- The compiler optimizes ChatGPT instructions for brevity\n- Large knowledge bases may need trimming\n\n## Gemini Gems setup\n\n### Creating a Gem\n\n1. Go to https://gemini.google.com/gems\n2. Create new Gem\n3. Paste instructions from `compiled/gemini-projects/instructions/{name}.md`\n\n### Knowledge files\n\n1. Upload files from `compiled/gemini-projects/knowledge/`\n2. Gemini limits: max 10 files\n3. The compiler bundles content to stay within limits\n\n### Gemini-specific optimizations\n\n- Instructions formatted for Gemini's style preferences\n- Knowledge bundled to minimize file count\n- Token counts optimized for Gemini's context window\n\n## Inheritance and personalized compilation\n\n### Baseline vs personalized\n\n- **Baseline**: Compile a repo standalone (`ragbot compile --project example-client`)\n- **Personalized**: Include inherited content (`ragbot compile --project m", "tokens": 1000, "metadata": {"source_file": "runbooks/system-config/llm-project-setup.md", "category": "runbooks", "chunk_index": 0, "total_chunks": 2, "start_char": 0, "end_char": 4000}}
{"id": "865be2d29a00", "text": "ge knowledge bases may need trimming\n\n## Gemini Gems setup\n\n### Creating a Gem\n\n1. Go to https://gemini.google.com/gems\n2. Create new Gem\n3. Paste instructions from `compiled/gemini-projects/instructions/{name}.md`\n\n### Knowledge files\n\n1. Upload files from `compiled/gemini-projects/knowledge/`\n2. Gemini limits: max 10 files\n3. The compiler bundles content to stay within limits\n\n### Gemini-specific optimizations\n\n- Instructions formatted for Gemini's style preferences\n- Knowledge bundled to minimize file count\n- Token counts optimized for Gemini's context window\n\n## Inheritance and personalized compilation\n\n### Baseline vs personalized\n\n- **Baseline**: Compile a repo standalone (`ragbot compile --project example-client`)\n- **Personalized**: Include inherited content (`ragbot compile --project example-client --personalized`)\n\nPersonalized compilation:\n1. Resolves inheritance chain (example-client \u2192 example-company \u2192 personal \u2192 ragbot)\n2. Merges content from all ancestors\n3. Outputs to `compiled/projects/{project}/` for the requesting user\n\n### When to use each\n\n| Use Case | Approach |\n|----------|----------|\n| Shared team project | Baseline compilation |\n| Personal Claude project | Personalized compilation |\n| Client workspace | Baseline (client-specific content only) |\n| Advisory work with personal identity | Personalized |\n\n## Context-filtered outputs\n\n### Available contexts\n\nContexts are defined in `source/contexts/` as YAML files:\n\n```yaml\n# writing-mode.yaml\nname: Writing Mode\ninclude:\n  instructions:\n    - identity.md\n    - voice-and-style.md\n  runbooks:\n    - writing/**\n    - content-creation/**\nexclude:\n  - runbooks/coding/**\ntoken_budget: 80000\n```\n\n### Using context outputs\n\nFor a writing-focused Claude project:\n1. Use standard instructions\n2. Upload content from `compiled/knowledge/by-context/writing-mode/`\n3. This excludes coding runbooks, engineering content\n\n## Updating projects\n\n### When to recompile\n\nRecompile when:\n- Source content changes\n- Inheritance relationships change\n- New contexts added\n- Token budget adjustments needed\n\n### Update workflow\n\n```bash\n# Recompile single project\nragbot compile --project {name}\n\n# Recompile all projects\nragbot compile --all\n\n# Force recompile (ignore cache)\nragbot compile --project {name} --force\n```\n\n### After recompilation\n\n1. Update custom instructions in LLM project\n2. Re-upload knowledge files (or trigger GitHub sync)\n3. Verify token counts in manifest.yaml\n\n## Troubleshooting\n\n### \"Instructions too long\"\n\n- Use context filtering to reduce scope\n- Move detailed content to knowledge files\n- Check manifest.yaml for token counts\n\n### \"Knowledge not being used\"\n\n- Verify files uploaded correctly\n- Check if content is in instructions vs knowledge\n- For Claude: ensure GitHub sync is active\n\n### \"Inheritance not working\"\n\n- Verify `my-projects.yaml` exists in personal repo\n- Check inheritance chain: `inherits_from` in compile-config.yaml\n- Run with `--verbose` to see inheritance resolution\n\n### \"Stale content\"\n\n- Use `--force` flag to ignore cache\n- Check compile timestamps in manifest.yaml\n- Verify source files are saved before compiling\n", "tokens": 780, "metadata": {"source_file": "runbooks/system-config/llm-project-setup.md", "category": "runbooks", "chunk_index": 1, "total_chunks": 2, "start_char": 3200, "end_char": 6322}}
{"id": "209c248c8b6a", "text": "# Prompt to combine Ragbot responses\n\nBelow these instructions is a document containing one or more prompts supplied to one or more LLM engines, along with the responses generated.\n\nPlease read through the entire document carefully. The document includes the original prompts along with all the responses from the LLM engine(s).\n\nYour task is to combine all the responses into a single, unified document. The goal is to merge the responses together in a coherent way, without leaving out any details, even minor ones, from any of the individual responses. It is critically important that you do not simplify, nor shorten, nor reduce any level of detail as you merge the responses. I don't want you to summarize anything. I want a very detailed combined response that is significantly longer and more detailed than even the longest of the input response. Under no circumstances should any part of your output response have less detail than any of the input responses. Please confirm that you understand this and that you will comply.\n\nI want you to also incorporate any relevant context or framing from the prompts where it would be helpful for understanding the responses.\n\nBefore generating the final document, please write out your plan for combining the responses inside a \"plan\" section. Consider how you will integrate the key points from each response and weave in useful context from the prompts.\n\nFinally, follow your plan and write out the unified document that combines all the responses inside a \"unified_document\" section. The unified document should be as comprehensive, detailed, and informative as possible. It should be well-formatted for ease of reading.\n\n<prompt_response_document>\n{{PROMPT_RESPONSE_DOCUMENT}}\n</prompt_response_document>\n", "tokens": 439, "metadata": {"source_file": "runbooks/system-config/response-synthesis.md", "category": "runbooks", "chunk_index": 0, "total_chunks": 1, "start_char": 0, "end_char": 1757}}
